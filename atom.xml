<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>MorningCoder</title>
  
  <subtitle>Coding make a better world</subtitle>
  <link href="/wangchenhust.github.io/atom.xml" rel="self"/>
  
  <link href="https://wangchenhust.github.io/"/>
  <updated>2020-06-28T03:59:53.183Z</updated>
  <id>https://wangchenhust.github.io/</id>
  
  <author>
    <name>WangChen</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>前端/JS/异步与Promise+async+await/弄懂 JavaScript 执行机制</title>
    <link href="https://wangchenhust.github.io/2020/06/28/%E5%89%8D%E7%AB%AF/JS/%E5%BC%82%E6%AD%A5%E4%B8%8EPromise+async+await/%E5%BC%84%E6%87%82%20JavaScript%20%E6%89%A7%E8%A1%8C%E6%9C%BA%E5%88%B6/"/>
    <id>https://wangchenhust.github.io/2020/06/28/%E5%89%8D%E7%AB%AF/JS/%E5%BC%82%E6%AD%A5%E4%B8%8EPromise+async+await/%E5%BC%84%E6%87%82%20JavaScript%20%E6%89%A7%E8%A1%8C%E6%9C%BA%E5%88%B6/</id>
    <published>2020-06-28T14:49:30.980Z</published>
    <updated>2020-06-28T03:59:53.183Z</updated>
    
    <content type="html"><![CDATA[<p>javascript是一门<strong>单线程</strong>语言，按照语句出现的顺序执行的，一切javascript版的”多线程”都是用单线程模拟出来的。</p><ul><li>同步任务</li><li>异步任务</li></ul><p>网页的渲染过程就是一大堆同步任务，比如页面骨架和页面元素的渲染。而像加载图片音乐之类占用资源大耗时久的任务，就是异步任务。<br><img src="https://user-gold-cdn.xitu.io/2017/11/21/15fdd88994142347?imageView2/0/w/1280/h/960/format/webp/ignore-error/1" alt="image"><br>以上循环过程就是常说的Event Loop(事件循环)。</p><p>怎么知道主线程执行栈为空啊？</p><p>js引擎存在<strong>monitoring process进程</strong>，会持续不断的检查主线程执行栈是否为空，一旦为空，就会去Event Queue那里检查是否有等待被调用的函数。<br>下面是一段简易的ajax请求代码：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">let data &#x3D; [];</span><br><span class="line">$.ajax(&#123;</span><br><span class="line">    url:www.javascript.com,</span><br><span class="line">    data:data,</span><br><span class="line">    success:() &#x3D;&gt; &#123;</span><br><span class="line">        console.log(&#39;发送成功!&#39;);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;)</span><br><span class="line">console.log(&#39;代码执行结束&#39;);</span><br></pre></td></tr></table></figure><ol><li>ajax进入Event Table，注册回调函数success。</li><li>执行console.log(‘代码执行结束’)。</li><li>ajax事件完成，回调函数success进入Event Queue。</li><li>主线程从Event Queue读取回调函数success并执行。</li></ol><h4 id="setTimeout"><a href="#setTimeout" class="headerlink" title="setTimeout"></a>setTimeout</h4><p>异步可以延时执行。setTimeout这个函数，是经过指定时间后，把要执行的任务加入到Event Queue中</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">setTimeout(() &#x3D;&gt; &#123;</span><br><span class="line">    task()</span><br><span class="line">&#125;,3000)</span><br><span class="line">sleep(10000000)</span><br></pre></td></tr></table></figure><p>执行过程：</p><ul><li>task()进入Event Table并注册,计时开始。</li><li>执行sleep函数，很慢，非常慢，计时仍在继续。</li><li>3秒到了，计时事件timeout完成，task()进入Event Queue，但是sleep也太慢了吧，还没执行完，只好等着。</li><li>sleep终于执行完了，task()终于从Event Queue进入了主线程执行。</li></ul><p>setTimeout(fn,0)是不是可以立即执行呢？</p><p>setTimeout(fn,0)的含义是，指定某个任务在主线程<strong>最早可得的空闲时间执行</strong>，意思就是不用再等多少秒了，只要主线程执行栈内的同步任务全部执行完成，栈为空就马上执行。【即便主线程为空，0毫秒实际上也是达不到的。根据HTML的标准，最低是4毫秒。】</p><h4 id="setInterval"><a href="#setInterval" class="headerlink" title="setInterval"></a>setInterval</h4><p>setInterval会每隔指定的时间将注册的函数置入Event Queue，如果前面的任务耗时太久，那么同样需要等待。对于setInterval(fn,ms)来说，我们已经知道不是每过ms秒会执行一次fn，而是每过ms秒，会有fn进入Event Queue。<strong>一旦setInterval的回调函数fn执行时间超过了延迟时间ms，那么就完全看不出来有时间间隔了</strong>。</p><h4 id="Promise与process-nextTick-callback"><a href="#Promise与process-nextTick-callback" class="headerlink" title="Promise与process.nextTick(callback)"></a>Promise与process.nextTick(callback)</h4><p>Promise:<a href="https://es6.ruanyifeng.com/#docs/promise" target="_blank" rel="noopener">https://es6.ruanyifeng.com/#docs/promise</a><br>process.nextTick(callback)类似node.js版的”setTimeout”，在事件循环的下一次循环中调用 callback 回调函数。</p><p>除了广义的同步任务和异步任务，我们对任务有更精细的定义：</p><ul><li>macro-task(宏任务)：包括整体代码script，setTimeout，setInterval</li><li>micro-task(微任务)：Promise，process.nextTick<br>不同类型的任务会进入对应的Event Queue.</li></ul><p>事件循环的顺序，决定js代码的执行顺序。进入整体代码(宏任务)后，开始第一次循环。接着执行所有的微任务。然后再次从宏任务开始，找到其中一个任务队列执行完毕，再执行所有的微任务。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">setTimeout(function() &#123;</span><br><span class="line">    console.log(&#39;setTimeout&#39;);</span><br><span class="line">&#125;)</span><br><span class="line"></span><br><span class="line">new Promise(function(resolve) &#123;</span><br><span class="line">    console.log(&#39;promise&#39;);</span><br><span class="line">&#125;).then(function() &#123;</span><br><span class="line">    console.log(&#39;then&#39;);</span><br><span class="line">&#125;)</span><br><span class="line"></span><br><span class="line">console.log(&#39;console&#39;);</span><br></pre></td></tr></table></figure><p>这段代码作为宏任务，进入主线程。</p><ul><li>先遇到setTimeout，那么将其回调函数注册后分发到宏任务Event Queue。(注册过程与上同，下文不再描述)</li><li>接下来遇到了Promise，new Promise立即执行，then函数分发到微任务Event Queue。</li><li>遇到console.log()，立即执行。</li><li>好啦，整体代码script作为第一个宏任务执行结束，看看有哪些微任务？我们发现了then在微任务Event Queue里面，执行。</li><li>ok，第一轮事件循环结束了，我们开始第二轮循环，当然要从宏任务Event Queue开始。我们发现了宏任务Event Queue中setTimeout对应的回调函数，立即执行。</li><li>结束。</li></ul><p>事件循环，宏任务，微任务的关系如图所示：<br><img src="https://user-gold-cdn.xitu.io/2017/11/21/15fdcea13361a1ec?imageView2/0/w/1280/h/960/format/webp/ignore-error/1" alt="image"></p><p>详细示例见：<a href="https://juejin.im/post/59e85eebf265da430d571f89#heading-2" target="_blank" rel="noopener">https://juejin.im/post/59e85eebf265da430d571f89#heading-2</a></p><p>总结：</p><p>(1)js的异步我们从最开头就说javascript是一门单线程语言，不管是什么新框架新语法糖实现的所谓异步，其实都是用同步的方法去模拟的，牢牢把握住单线程这点非常重要。</p><p>(2)事件循环Event Loop事件循环是js实现异步的一种方法，也是js的执行机制。</p><p>(3)javascript的执行和运行执行和运行有很大的区别，javascript在不同的环境下，比如node，浏览器，Ringo等等，执行方式是不同的。而运行大多指javascript解析引擎，是统一的。</p><p>(4)setImmediate微任务和宏任务还有很多种类，比如setImmediate等等，执行都是有共同点的。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;javascript是一门&lt;strong&gt;单线程&lt;/strong&gt;语言，按照语句出现的顺序执行的，一切javascript版的”多线程”都是用单线程模拟出来的。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;同步任务&lt;/li&gt;
&lt;li&gt;异步任务&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;网页的渲染过程就是一
      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>前端/VUE/vue的生命周期</title>
    <link href="https://wangchenhust.github.io/2020/06/20/%E5%89%8D%E7%AB%AF/VUE/vue%E7%9A%84%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F/"/>
    <id>https://wangchenhust.github.io/2020/06/20/%E5%89%8D%E7%AB%AF/VUE/vue%E7%9A%84%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F/</id>
    <published>2020-06-20T08:26:54.641Z</published>
    <updated>2020-06-20T08:26:54.855Z</updated>
    
    <content type="html"><![CDATA[<h2 id="vue的生命周期"><a href="#vue的生命周期" class="headerlink" title="vue的生命周期"></a>vue的生命周期</h2><p>Vue 实例有一个完整的生命周期，也就是从<strong>开始创建、初始化数据、编译模板、挂载Dom→渲染、更新→渲染、卸载等</strong>一系列过程，我们称这是 Vue 的生命周期。通俗说就是 Vue 实例从创建到销毁的过程，就是生命周期。</p><p>beforeCreate: vue元素的挂载元素el和数据都为undefined，还未初始化；</p><p>created：vue实例的数据对象data有了，el还没有；</p><p>beforeMount：vue实例的$el和data都初始化了，但是还挂载在之前的虚拟dom节点上，data.message还未替换；</p><p>mounted：vue实例挂载完成，data.message成功渲染。</p><p>更新前后：data变化时会触发beforeUpdate和updated方法；</p><p>销毁前后：beforeDestory和destoryed，在执行destoryed方法后，对data的改变不会触发周期函数，说明vue实例已经解除了事件监听以及dom绑定，但是dom结构依然存在；</p><p>vue生命周期的作用：</p><p>他的生命周期中有多个事件钩子，让我们控制整个vue实例的过程时更容易形成良好的逻辑。</p><p>生命周期钩子的一些使用方法：</p><p>beforeCreate：loading事件，在加载实例时触发。</p><p>created：初始化完成事件，异步请求。</p><p>mounted：挂载元素，获取dom节点</p><p>uptaded：对数据统一处理</p><p>beforeDestory：确认事件停止。</p><p>nextTick：更新数据后立即操作dom。</p><h2 id="computed和watch的区别"><a href="#computed和watch的区别" class="headerlink" title="computed和watch的区别"></a>computed和watch的区别</h2><p>computed</p><p>计算结果并返回，只有当被计算的<strong>属性发生改变</strong>时才会触发（即：计算属性的结果会被缓存，除非依赖的响应属性变化才会重新计算）</p><p>watch<br> 监听某一个值，当被监听的<strong>值发生变化</strong>时，执行相关操作。（与computed的区别是，watch更加适用于监听某一个值得变化，并做对应操作，比如请求后太接口等。而computed适用于计算已有的值并返回结果。）</p><p>监听简单数据类型：<br>data(){<br>      return{<br>        ‘first’:2<br>      }<br>    },<br>    watch:{<br>      first(){<br>        console.log(this.first)<br>      }<br>    },</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;vue的生命周期&quot;&gt;&lt;a href=&quot;#vue的生命周期&quot; class=&quot;headerlink&quot; title=&quot;vue的生命周期&quot;&gt;&lt;/a&gt;vue的生命周期&lt;/h2&gt;&lt;p&gt;Vue 实例有一个完整的生命周期，也就是从&lt;strong&gt;开始创建、初始化数据、编译模板、挂
      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>深度学习/VGG</title>
    <link href="https://wangchenhust.github.io/2020/04/06/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/VGG/"/>
    <id>https://wangchenhust.github.io/2020/04/06/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/VGG/</id>
    <published>2020-04-05T17:43:39.150Z</published>
    <updated>2020-04-24T13:41:54.865Z</updated>
    
    <content type="html"><![CDATA[<p><img src="D:%5Csoftdownload%5COffice%5C%E6%9C%89%E9%81%93%E4%BA%91%5CFile%5Cwangchen_hust@163.com%5C54fb94ca8f5e417888f31d4637b9c2f5%5Cclipboard.png" alt="img"></p><p><img src="D:%5Csoftdownload%5COffice%5C%E6%9C%89%E9%81%93%E4%BA%91%5CFile%5Cwangchen_hust@163.com%5Ca38e9559ddc24214966f6ef1895e5202%5Cclipboard.png" alt="img"></p><p>使用很小的卷积（3*3），增加网络深度可以有效提升模型的效果，而且VGGNet对其他数据集具有很好的泛化能力。<a id="more"></a></p><p>在结构上，VGGnet其实和一开始的AlexNet在结构上没有什么太大的差别，不同的就是：</p><ol><li>卷积层使用更小的尺寸和间隔(kernel size=3, stride=1), AlexNet(kernel size=11, stride=4)。然后更加的深了。这样可以减少参数（论文中有举例），并且可以得到更多的特征，经过三层非线性激活函数也增加了非线性的特性。</li><li>然后VGGNet使用了1X1卷积核。作用是可以在保持feature map 尺寸不变（即不损失分辨率）的前提下大幅增加非线性特性，把网络做得很深。对于1X1卷积核，下面要讲的GoogLeNet和ResNet同样使用了，具体的下面讲。</li><li>虽然比于AlexNet网络更深，但文章推测VGGNet在更少的周期内就能收敛，原因有二个，一个是更大的深度和更小的卷积带来隐式的正则化；第二个是一些层的预训练。</li><li>最后是VGGNet不使用局部响应标准化(LRN)，因为这样的标准化并不能在ILSVRC数据集上提升性能，却导致更多的内存消耗和计算时间。</li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;D:%5Csoftdownload%5COffice%5C%E6%9C%89%E9%81%93%E4%BA%91%5CFile%5Cwangchen_hust@163.com%5C54fb94ca8f5e417888f31d4637b9c2f5%5Cclipboard.png&quot; alt=&quot;img&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;D:%5Csoftdownload%5COffice%5C%E6%9C%89%E9%81%93%E4%BA%91%5CFile%5Cwangchen_hust@163.com%5Ca38e9559ddc24214966f6ef1895e5202%5Cclipboard.png&quot; alt=&quot;img&quot;&gt;&lt;/p&gt;
&lt;p&gt;使用很小的卷积（3*3），增加网络深度可以有效提升模型的效果，而且VGGNet对其他数据集具有很好的泛化能力。
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>深度学习/GoogleNet</title>
    <link href="https://wangchenhust.github.io/2020/04/06/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/GoogleNet/"/>
    <id>https://wangchenhust.github.io/2020/04/06/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/GoogleNet/</id>
    <published>2020-04-05T17:43:21.263Z</published>
    <updated>2020-04-24T13:42:27.082Z</updated>
    
    <content type="html"><![CDATA[<p><img src="D:%5Csoftdownload%5COffice%5C%E6%9C%89%E9%81%93%E4%BA%91%5CFile%5Cwangchen_hust@163.com%5Cb84785a3805949a4839b5d79288b1560%5Cclipboard.png" alt="img"></p><p>Inception结构：</p><p>造一种“基础神经元”结构，来搭建一个稀疏性、高计算性能的网络结构。<a id="more"></a></p><p>采用不同大小的卷积核表示不同大小的感受野，后面的拼接表示不同尺度特征的融合，其中卷积核大小采用1、3和5，这主要是为了方便对齐。然后网络越到后面，特征就越抽象，空间集中性会降低，需要的感受野更大，因此3x3和5x5的卷积核在更高层会比较多。还有就是pooling层的加入效果更好，所以在中间也加了pooling层，提高效率。</p><p><img src="D:%5Csoftdownload%5COffice%5C%E6%9C%89%E9%81%93%E4%BA%91%5CFile%5Cwangchen_hust@163.com%5C97a9430d83a246529990f53322c9dd62%5Cclipboard.png" alt="img"></p><p>1×1卷积降维：</p><p>前面因为使用3x3或者5x5的卷积核仍然会带来巨大的计算量。 因此，文章借鉴NIN，采用1x1卷积核来降维，从而减少参数。</p><p>Inception的架构的两个主要优点：</p><p>一是允许显著增加每一步的单元数目，计算复杂性不会不受控制。降维的普遍使用能保护最后一步到下一层的大量输入滤波器，在对它们用大的patch size卷积前首先降维。</p><p>二是视觉信息在不同的尺度上进行处理然后聚合，这样下一步可以同时从不同尺度提取特征。 采用了Inception模块的网络要比没有采用Inception模块的同样架构的网络快2~3倍。</p><p><img src="D:%5Csoftdownload%5COffice%5C%E6%9C%89%E9%81%93%E4%BA%91%5CFile%5Cwangchen_hust@163.com%5Cb918cbfbd4f34ebda8230d44a444df1f%5Cclipboard.png" alt="img"></p><p><img src="D:%5Csoftdownload%5COffice%5C%E6%9C%89%E9%81%93%E4%BA%91%5CFile%5Cwangchen_hust@163.com%5C6006a7222c0f48b29b56147c3a9f286c%5Cclipboard.png" alt="img"></p><p>VGG</p><p>提升网络性能最直接的办法就是<strong>增加网络深度和宽度</strong>，这也就意味着巨量的参数。但是，巨量参数容易产生过拟合也会大大增加计算量。而本文<strong>为了稀疏矩阵聚类为较为密集的子矩阵</strong>来提高计算性能，提出了名为Inception 的结构，并以此来解决网络深度变得很深所带来的计算量和性能问题。</p><p>总体构架ImageNet比赛上一共22层，比VGG还多几层。</p><p>参考：<a href="https://zhuanlan.zhihu.com/p/33528315" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/33528315</a></p><p>inception变式见：  <a href="https://my.oschina.net/u/876354/blog/1637819" target="_blank" rel="noopener">  大话CNN经典模型：GoogLeNet</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;D:%5Csoftdownload%5COffice%5C%E6%9C%89%E9%81%93%E4%BA%91%5CFile%5Cwangchen_hust@163.com%5Cb84785a3805949a4839b5d79288b1560%5Cclipboard.png&quot; alt=&quot;img&quot;&gt;&lt;/p&gt;
&lt;p&gt;Inception结构：&lt;/p&gt;
&lt;p&gt;造一种“基础神经元”结构，来搭建一个稀疏性、高计算性能的网络结构。
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>深度学习/CNN</title>
    <link href="https://wangchenhust.github.io/2020/04/06/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/CNN/"/>
    <id>https://wangchenhust.github.io/2020/04/06/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/CNN/</id>
    <published>2020-04-05T17:43:00.351Z</published>
    <updated>2020-04-24T13:42:38.100Z</updated>
    
    <content type="html"><![CDATA[<p>CNN历史演化图：</p><p><img src="D:%5Csoftdownload%5COffice%5C%E6%9C%89%E9%81%93%E4%BA%91%5CFile%5Cwangchen_hust@163.com%5C568550a171da407dbe93d7b276563567%5Cclipboard.png" alt="img"></p><p><img src="D:%5Csoftdownload%5COffice%5C%E6%9C%89%E9%81%93%E4%BA%91%5CFile%5Cwangchen_hust@163.com%5Cb9aa6453459a4c4f893dfacc869fc631%5Cclipboard.png" alt="img"></p><p><strong>ImageNet挑战赛总结</strong></p><p>从2009到2017，ImageNet的8年历史，真可谓是直接代表深度学习的革命引领。先看下图：</p><p><img src="D:%5Csoftdownload%5COffice%5C%E6%9C%89%E9%81%93%E4%BA%91%5CFile%5Cwangchen_hust@163.com%5Cfe4107b655b74e6ab5b42c0d466474f2%5C23818_1440w.jpeg" alt="img"></p><p>可以看到，一年一年都有结构上的创新，不止深度上的变化，top 5 error也从28.2%到3.57%（top 5 error，表示最后概率向量最大的前五名中出现了正确概率即为预测正确。上面的表示错误率），超过了接受过训练的人在ImageNet数据集上对图片进行分类的成绩（5.1%）。<a id="more"></a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;CNN历史演化图：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;D:%5Csoftdownload%5COffice%5C%E6%9C%89%E9%81%93%E4%BA%91%5CFile%5Cwangchen_hust@163.com%5C568550a171da407dbe93d7b276563567%5Cclipboard.png&quot; alt=&quot;img&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;D:%5Csoftdownload%5COffice%5C%E6%9C%89%E9%81%93%E4%BA%91%5CFile%5Cwangchen_hust@163.com%5Cb9aa6453459a4c4f893dfacc869fc631%5Cclipboard.png&quot; alt=&quot;img&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ImageNet挑战赛总结&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;从2009到2017，ImageNet的8年历史，真可谓是直接代表深度学习的革命引领。先看下图：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;D:%5Csoftdownload%5COffice%5C%E6%9C%89%E9%81%93%E4%BA%91%5CFile%5Cwangchen_hust@163.com%5Cfe4107b655b74e6ab5b42c0d466474f2%5C23818_1440w.jpeg&quot; alt=&quot;img&quot;&gt;&lt;/p&gt;
&lt;p&gt;可以看到，一年一年都有结构上的创新，不止深度上的变化，top 5 error也从28.2%到3.57%（top 5 error，表示最后概率向量最大的前五名中出现了正确概率即为预测正确。上面的表示错误率），超过了接受过训练的人在ImageNet数据集上对图片进行分类的成绩（5.1%）。
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>深度学习/ResNet</title>
    <link href="https://wangchenhust.github.io/2020/04/06/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/ResNet/"/>
    <id>https://wangchenhust.github.io/2020/04/06/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/ResNet/</id>
    <published>2020-04-05T17:42:38.343Z</published>
    <updated>2020-04-24T13:42:03.527Z</updated>
    
    <content type="html"><![CDATA[<p>网络的层数越多，意味着能够提取到不同level的特征越丰富。并且，越深的网络提取的特征越抽象，越具有语义信息。但如果简单地增加深度，会导致<strong>梯度弥散或梯度爆炸</strong>。即使是增加正则化初始化和中间的正则化层（Batch Normalization），也只能到几十层的网络。如果变得更深，就会出<strong>现退化问题</strong>，所谓的退化问题，就是随着网络层数增加，但是在训练集上的准确率却饱和甚至下降了。这个不能解释为overfitting，因为overfit应该表现为在训练集上表现更好才对。退化问题也说明了深度网络不能很简单地被很好地优化。<a id="more"></a></p><p>如果深层网络的后面那些层是恒等映射，那么模型就退化为一个浅层网络。那现在要解决的就是学习恒等映射函数了。 但是直接让一些层去拟合一个潜在的恒等映射函数H(x) = x，比较困难，这可能就是深层网络难以训练的原因。但是，如果把网络设计为H(x) = F(x) + x,如下图。我们可以转换为学习一个残差函数F(x) = H(x) - x. 只要F(x)=0，就构成了一个恒等映射H(x) = x. 而且，拟合残差肯定更加容易。</p><p><strong>残差块结构</strong></p><p>借鉴了Highway Network思想的网络 （残差网络） 在2015名声大噪。该相当于旁边专门开个通道使得输入可以直达输出，而优化的目标由原来的拟合输出H(x)变成输出和输入的差H(x)-x，其中H(X)是某一层原始的的期望映射输出，x是输入。</p><p><img src="D:%5Csoftdownload%5COffice%5C%E6%9C%89%E9%81%93%E4%BA%91%5CFile%5Cwangchen_hust@163.com%5C38e0481e42454d028e5d6902a685afb4%5Cclipboard.png" alt="img"></p><p>实验证明，这个残差块往往<strong>需要两层以上</strong>，单单一层的残差块(y=W1x+x)并不能起到提升作用。</p><p>同时下面借用知乎用户<a href="https://www.zhihu.com/people/5004ad407abca0f38da16504192f77e5" target="_blank" rel="noopener">@The one</a>在<a href="https://www.zhihu.com/question/53224378" target="_blank" rel="noopener">resnet（残差网络）的F（x）究竟长什么样子？</a>的回答，进一步理解残差网络：</p><p>上面F是求和前网络映射，H是从输入到求和后的网络映射。</p><p>比如把5映射到5.1，</p><p>那么引入残差前是F’(5)=5.1，</p><p>引入残差后是H(5)=5.1, H(5)=F(5)+5, F(5)=0.1。</p><p>这里的F’和F都表示网络参数映射，引入残差后的映射对输出的变化更敏感。比如原来是从5.1到5.2，映射F’的输出增加了1/51=2%，而对于残差结构从5.1到5.2，映射F是从0.1到0.2，增加了100%。明显后者输出变化对权重的调整作用更大，所以效果更好。</p><p>残差的思想都是去掉相同的主体部分，从而突出微小的变化，看到残差网络我第一反应就是差分放大器…</p><p><strong>从building block到bottleneck</strong></p><p>考虑计算的成本，对残差块做了计算优化，即将两个3x3的卷积层替换为1x1 + 3x3 + 1x1, 如下图。新结构中的中间3x3的卷积层首先在一个降维1x1卷积层下减少了计算，然后在另一个1x1的卷积层下做了还原，既保持了精度又减少了计算量。</p><p><img src="D:%5Csoftdownload%5COffice%5C%E6%9C%89%E9%81%93%E4%BA%91%5CFile%5Cwangchen_hust@163.com%5C8dd7b568c4d048b7a0ecec5480ba514e%5Cclipboard.png" alt="img"></p><p>这两种结构是分别针对<strong>ResNet34和ResNet50/101/152</strong>，右边的“bottleneck design”要比左边的“building block”多了1层，增添1*1的卷积目的就是为了降低参数的数目，减少计算量。所以浅层次的网络，可使用“building block”，对于深层次的网络，为了减少计算量，bottleneck desigh 是更好的选择。</p><p>再将x添加到F(x)中，还需考虑到x的维度与F(x)维度可能不匹配的情况，论文中给出三种方案：</p><p>A: 输入输出一致的情况下，使用恒等映射，不一致的情况下，则用0填充(zero-padding shortcuts)</p><p>B: 输入输出一致时使用恒等映射，不一致时使用 projection shortcuts</p><p>C: 在两种情况下均使用 projection shortcuts</p><p>经实验验证，虽然C要稍优于B，B稍优于A，但是A/B/C之间的稍许差异对解决“退化”问题并没有多大的贡献，而且使用0填充时，不添加额外的参数，可以保证模型的复杂度更低，这对更深的网络非常有利的，因此方法C被作者舍弃。</p><p>和GooLeNet一样，ResNet同样也利用了1×1卷积，并且是在3×3卷积层的<strong>前后</strong>都使用了，不仅进行了降维，还进行了升维，使得卷积层的输入和输出的通道数都减小，参数数量进一步减少。</p><p>常见的ResNet网络架构的组成，如下所示：</p><p><img src="D:%5Csoftdownload%5COffice%5C%E6%9C%89%E9%81%93%E4%BA%91%5CFile%5Cwangchen_hust@163.com%5Cf9af540abca7483b8448804907b3518d%5Cclipboard.png" alt="img"></p><p><img src="D:%5Csoftdownload%5COffice%5C%E6%9C%89%E9%81%93%E4%BA%91%5CFile%5Cwangchen_hust@163.com%5C95e7a392a6ec450faf97197b7030f625%5Cclipboard.png" alt="img"></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;网络的层数越多，意味着能够提取到不同level的特征越丰富。并且，越深的网络提取的特征越抽象，越具有语义信息。但如果简单地增加深度，会导致&lt;strong&gt;梯度弥散或梯度爆炸&lt;/strong&gt;。即使是增加正则化初始化和中间的正则化层（Batch Normalization），也只能到几十层的网络。如果变得更深，就会出&lt;strong&gt;现退化问题&lt;/strong&gt;，所谓的退化问题，就是随着网络层数增加，但是在训练集上的准确率却饱和甚至下降了。这个不能解释为overfitting，因为overfit应该表现为在训练集上表现更好才对。退化问题也说明了深度网络不能很简单地被很好地优化。
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>深度学习/Network in Network</title>
    <link href="https://wangchenhust.github.io/2020/04/06/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/Network%20in%20Network/"/>
    <id>https://wangchenhust.github.io/2020/04/06/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/Network%20in%20Network/</id>
    <published>2020-04-05T17:42:10.119Z</published>
    <updated>2020-04-24T13:42:11.120Z</updated>
    
    <content type="html"><![CDATA[<p>这是14年ICLR的一篇paper，虽不是在imagenet上的冠军模型，但其采用了少量的参数就松松击败了Alexnet网络，Alexnet网络参数大小是230M，采用这篇paper的算法仅仅29M。<a id="more"></a></p><p>该论文主要的contribution是提出mlpconv，相比于传统的卷积神经网络来说不易过拟合，而且可以进行全局平均池化。下面具体讲述一些创新点：</p><p><strong>卷积层的改进–mlpconv</strong></p><p>之前同样的卷积层可以认为是线性的, 因为只是局部接收域与卷积核进行加权求和，然后可能接一个relu激活函数，但它的抽象提取特征的能力还是不够的。所以，在这篇文章中，引入了mlpconv。提出了 mlpcon 结构，它用多层的感知器（多层的全连接层）来替代单纯的卷积神经网络中的加权求和，也就是原来的feature map经过MLP的映射再输出。其中 mlpcon 指的是： multilayer perceptron + convolution，mlp被共享于所有的局部感受野。如下图所示：</p><p><img src="D:%5Csoftdownload%5COffice%5C%E6%9C%89%E9%81%93%E4%BA%91%5CFile%5Cwangchen_hust@163.com%5C0895d8da88424fe79ce4dc578b626de7%5Cclipboard.png" alt="img"></p><p>其实和原来的差别就体现在中间接了MLP层，这样可以提高其非线性。如上图右，提高每一层卷积层对于复杂特征的识别能力，这里举个可能不那么恰当的例子，传统的CNN网络，每一层的卷积层相当于一个只会做单一任务，你必须要增加海量的卷积核来达到完成特定量类型的任务，而MLPconv的每层conv有更加大的能力，每一层能够做多种不同类型的任务，在选择卷积核时只需要很少量的部分</p><p><strong>整体结构</strong></p><p>可以看到就是多个MLPconv结构组合，再之后接上global average pooling组成：</p><p><img src="D:%5Csoftdownload%5COffice%5C%E6%9C%89%E9%81%93%E4%BA%91%5CFile%5Cwangchen_hust@163.com%5C4e2d08c5a72048359e9d7ae039937921%5Cclipboard.png" alt="img"></p><p><strong>1×1卷积的作用</strong></p><p>1×1的卷积层引起人们的重视应该就是在NIN的结构中，论文中利用MLP代替传统的线性卷积核，从而提高网络的表达能力。文中同时利用了跨通道pooling的角度解释，认为文中提出的MLP其实等价于在传统卷积核后面接cccp层，从而实现多个feature map的线性组合，实现跨通道的信息整合。而cccp层是等价于1×1卷积的，因此细看NIN的caffe实现，就是在每个传统卷积层后面接了两个cccp层（其实就是接了两个1×1的卷积层）。这就实现跨通道的交互和信息整合。</p><p><strong>使用全局均值池化</strong></p><p>论文中还采用全局均值池化来解决传统CNN网络中最后全连接层参数过于复杂的特点，而且全连接会造成网络的泛化能力差，（Alexnet中使用dropout来提高网络的泛化能力)，至于global average pooling 与average pooling的区别如下<strong>:</strong></p><p>如最后一个卷积层输出10个feature map，average pooling 是对每个feature map分别求平均，输出10个feature map。 global average pooling是对每个feature map内部取平均，每个feature map变成一个值（因为kernel的大小设置成和feature map的相同），10个feature map就变成一个10维的向量，然后直接输入到softmax中。如下图</p><p><img src="D:%5Csoftdownload%5COffice%5C%E6%9C%89%E9%81%93%E4%BA%91%5CFile%5Cwangchen_hust@163.com%5C64600e6767f4430880d655c67f4e5c49%5C5f10a_1440w.jpeg" alt="img"></p><p>其实简单理解就是在原始的CNN中10个feature map的话经过average pooling输出的不一定是一个值，而global average pooling输出的就一定是一个值</p><p>最后附上原文：<a href="https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/1312.4400.pdf">Network In Network</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;这是14年ICLR的一篇paper，虽不是在imagenet上的冠军模型，但其采用了少量的参数就松松击败了Alexnet网络，Alexnet网络参数大小是230M，采用这篇paper的算法仅仅29M。
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>深度学习/AlexNet</title>
    <link href="https://wangchenhust.github.io/2020/04/06/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/AlexNet/"/>
    <id>https://wangchenhust.github.io/2020/04/06/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/AlexNet/</id>
    <published>2020-04-05T17:41:45.998Z</published>
    <updated>2020-04-24T13:42:53.127Z</updated>
    
    <content type="html"><![CDATA[<p>2012年，AlexNet在ImageNet图像分类任务竞赛中获得冠军，一鸣惊人，从此开创了深度神经网络空前的高潮。</p><p>优势：</p><ul><li>使用了非线性激活函数ReLU（其效果在较深的网络超过Sigmoid，成功解决了Sigmoid在网络较深时的梯度弥散问题。Relu比tanh快差不多6倍)</li><li>提出了LRN（Local Response Normalization），局部响应归一化，LRN一般用在激活和池化函数后，对局部神经元的活动创建竞争机制，使其中响应比较大对值变得相对更大，并抑制其他反馈较小的神经元，增强了模型的泛化能力。ReLU本来是不需要对输入进行标准化的，但在篇论文中发现进行局部标准化能提高性能。然后设计了LRN，灵感来源于生物的神经结构，也就是活跃的神经元对相邻神经元的抑制现象（侧抑制）。<a id="more"></a></li><li>使用CUDA加速深度神经卷积网络的训练，利用GPU强大的并行计算能力，处理神经网络训练时大量的矩阵运算</li><li>在CNN中使用重叠的最大池化，AlexNet全部使用最大池化，避免平均池化的模糊化效果。AlexNet中提出让步长比池化核的尺寸小，这样池化层的输出之间会有重叠和覆盖，提升了特征的丰富性。</li><li>使用数据增广（data agumentation）和Dropout防止过拟合。【数据增广】随机地从256256的原始图像中截取224224大小的区域，相当于增加了2048倍的数据量；【Dropout】AlexNet在后面的三个全连接层中使用Dropout，随机忽略一部分神经元，以避免模型过拟合</li></ul><ol><li>大量数据，Deep Learning领域应该感谢李飞飞团队搞出来如此大的标注数据集合ImageNet；</li><li>GPU，这种高度并行的计算神器确实助了洪荒之力，没有神器在手，Alex估计不敢搞太复杂的模型；</li><li>算法的改进，包括网络变深、数据增强、ReLU、Dropout等</li></ol><p>使用<strong>梯度下降法</strong>的多层网络可以从大量的数据中学习复杂的，高纬，非线性的映射，这使得他们成为图像识别任务的首选。 全连接的多层网络可以作为分类器。</p><p>首先，图像是非常大的，由很多像素组成。具有100个隐藏单元的全连接网络包含成千上万的权重。为了解决系统的消耗和内存占用问题，在下面描述的卷积神经网络中，位移不变性(shift invariance)可以通过<strong>权值共享</strong>实现。</p><p>全连接的网络的另一个缺点就是完全忽略了输入的拓扑结构。在不影响训练的结果的情况下，输入图像可以是任意的顺序。CNN通过将<strong>隐藏结点的感受野限制在局部来提取特征</strong>。</p><p>CNN通过局部感受野(local receptive fields)，权值共享(shared weights)，下采样(sub-sampling)实现位移，缩放，和形变的不变性(shift,scale,distortion invariance)。</p><p><strong>卷积层的核就是特征图中所有单元使用的一组连接权重</strong>。卷积层的一个重要特性是如果输入图像发生了位移，特征图会发生相应的位移，否则特征图保持不变。这个特性是CNN<strong>对位移和形变保持鲁棒</strong>的基础。</p><p>一旦计算出feature map,那么精确的位置就变得不重要了，<strong>相对于其他特征的大概位置是才是相关的</strong>。</p><p>在特征图中降低特征位置的精度的方式是降低特征图的空间分辨率，这个可以通过下采样层达到，下采样层通过求局部平均降低特征图的分辨率，并且降低了输出对平移和形变的敏感度。 </p><p><img src="D:%5Csoftdownload%5COffice%5C%E6%9C%89%E9%81%93%E4%BA%91%5CFile%5Cwangchen_hust@163.com%5C002ce68811d84a62b505b65eba0d5478%5Cclipboard.png" alt="img"></p><p>Alexnet用了两个GPU来进行训练，然后卷积只在某一层进行交叉链接。这样可以加快训练，但效果也不会被影响。</p><p>AlexNet总共包含8层，其中有5个卷积层和3个全连接层，有60M个参数，神经元个数为650k，分类数目为1000，LRN层出现在第一个和第二个卷积层后面，最大池化层出现在两个LRN层及最后一个卷积层后。</p><p>第一层卷积层使用96个大小为11x11x3的卷积核对224x224x3的输入图像以4个像素为步长（这是核特征图中相邻神经元感受域中心之间的距离）进行滤波。</p><p>第二层卷积层将第一层卷积层的输出（经过响应归一化和池化）作为输入，并使用256个大小为5x5x48的核对它进行滤波。</p><p>第三层、第四层和第五层的卷积层在没有任何池化或者归一化层介于其中的情况下相互连接。</p><p>第三层卷积层有384个大小为3x3x256的核与第二层卷积层的输出（已归一化和池化）相连。</p><p>第四层卷积层有384个大小为3x3x192的核，第五层卷积层有256个大小为 的核。每个全连接层有4096个神经元。</p><p>饱和的非线性函数比不饱和非线性函数f(x)=max(0,x)更慢。使用ReLUs的深度卷积神经网络训练速度比同样情况下使用tanh单元的速度快好几倍。ReLUs主要是对训练集的拟合进行加速。快速学习对由大规模数据集上训练出大模型的性能有相当大的影响。</p><p>用ReLU代替了传统的Tanh或者Logistic: </p><p>​        ReLU本质上是分段线性模型，前向计算非常简单，无需指数之类操作；</p><p>​        ReLU的偏导也很简单，反向传播梯度，无需指数或者除法之类操作；</p><p>​        ReLU不容易发生梯度发散问题，Tanh和Logistic激活函数在两端的时候导数容易趋近于零，多级连乘后梯度更加约等于0；</p><p>​        ReLU关闭了右边，从而会使得很多的隐层输出为0，即网络变得稀疏，起到了类似L1的正则化作用，可以在一定程度上缓解过拟合。 </p><p>ReLUs具有符合本文要求的一个性质：它不需要对输入进行归一化来防止饱和。</p><p>只要一些训练样本产生一个正输入给一个ReLU，那么在那个神经元中学习就会开始。</p><p>但是，我们还是发现如下的局部标准化方案有助于增加泛化性能。</p><p><strong>2.2 降低过拟合( Reducing Overfitting)</strong></p><p><strong>数据增强(Data Augmentation)</strong></p><ul><li>方法1：生成<strong>平移图像和水平翻转图像</strong>。做法就是从256x256的图像中提取随机的224x224大小的块（以及它们的水平翻转），然后基于这些提取的块训练网络。softmax层对这十个块做出的预测取均值。</li><li>方法2：改变<strong>训练图像的RGB通道的强度</strong>。特别的，本文对整个ImageNet训练集的RGB像素值进行了PCA。对每一幅训练图像，本文加上多倍的主成分，倍数的值为相应的特征值乘以一个均值为0标准差为0.1的高斯函数产生的随机变量。</li></ul><p><strong>Dropout</strong></p><ul><li>它将每一个隐藏神经元的输出以50%的概率设为0。这些以这种方式被“踢出”的神经元不会参加前向传递，也不会加入反向传播。因此每次有输入时，神经网络采样一个不同的结构，但是所有这些结构都共享权值。这个技术降低了神经元之间复杂的联合适应性。 Dropout方法和数据增强一样，都是防止过拟合的。Dropout应该算是AlexNet中一个很大的创新</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;2012年，AlexNet在ImageNet图像分类任务竞赛中获得冠军，一鸣惊人，从此开创了深度神经网络空前的高潮。&lt;/p&gt;
&lt;p&gt;优势：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;使用了非线性激活函数ReLU（其效果在较深的网络超过Sigmoid，成功解决了Sigmoid在网络较深时的梯度弥散问题。Relu比tanh快差不多6倍)&lt;/li&gt;
&lt;li&gt;提出了LRN（Local Response Normalization），局部响应归一化，LRN一般用在激活和池化函数后，对局部神经元的活动创建竞争机制，使其中响应比较大对值变得相对更大，并抑制其他反馈较小的神经元，增强了模型的泛化能力。ReLU本来是不需要对输入进行标准化的，但在篇论文中发现进行局部标准化能提高性能。然后设计了LRN，灵感来源于生物的神经结构，也就是活跃的神经元对相邻神经元的抑制现象（侧抑制）。
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>深度学习/LeNet</title>
    <link href="https://wangchenhust.github.io/2020/04/06/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/LeNet/"/>
    <id>https://wangchenhust.github.io/2020/04/06/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/LeNet/</id>
    <published>2020-04-05T17:41:02.788Z</published>
    <updated>2020-04-24T13:42:17.535Z</updated>
    
    <content type="html"><![CDATA[<p>手写字体识别模型LeNet5诞生于1994年，是最早的卷积神经网络之一。LeNet5通过巧妙的设计，利用卷积、参数共享、池化等操作提取特征，避免了大量的计算成本，最后再使用全连接神经网络进行分类识别，这个网络也是最近大量神经网络架构的起点。<a id="more"></a></p><p><img src="D:%5Csoftdownload%5COffice%5C%E6%9C%89%E9%81%93%E4%BA%91%5CFile%5Cwangchen_hust@163.com%5C3c13e6bdf8fc48e29f0c588a2e1a7fff%5Cclipboard.png" alt="img"></p><p>LeNet5由7层CNN（不包含输入层）组成，上图中输入的原始图像大小是32×32像素，卷积层用Ci表示，子采样层（pooling，池化）用Si表示，全连接层用Fi表示。下面逐层介绍其作用和示意图上方的数字含义。</p><p>1、C1层（卷积层）：6@28×28</p><p>该层使用了6个卷积核，每个卷积核的大小为5×5，这样就得到了6个feature map（特征图）。</p><p>（1）特征图大小</p><p>每个卷积核（5×5）与原始的输入图像（32×32）进行卷积，这样得到的feature map（特征图）大小为（32-5+1）×（32-5+1）= 28×28</p><p>卷积核与输入图像按卷积核大小逐个区域进行匹配计算，匹配后原始输入图像的尺寸将变小，因为边缘部分卷积核无法越出界，只能匹配一次，匹配计算后的尺寸变为Cr×Cc=（Ir-Kr+1）×（Ic-Kc+1），其中Cr、Cc，Ir、Ic，Kr、Kc分别表示卷积后结果图像、输入图像、卷积核的行列大小。</p><p>（2）参数个数</p><p>由于参数（权值）共享的原因，对于同个卷积核每个神经元均使用相同的参数，因此，参数个数为（5×5+1）×6= 156，其中5×5为卷积核参数，1为偏置参数</p><p>（3）连接数</p><p>卷积后的图像大小为28×28，因此每个特征图有28×28个神经元，每个卷积核参数为（5×5+1）×6，因此，该层的连接数为（5×5+1）×6×28×28=122304</p><p>2、S2层（下采样层，也称池化层）：6@14×14</p><p>（1）特征图大小</p><p>这一层主要是做池化或者特征映射（特征降维），池化单元为2×2，因此，6个特征图的大小经池化后即变为14×14。回顾本文刚开始讲到的池化操作，池化单元之间没有重叠，在池化区域内进行聚合统计后得到新的特征值，因此经2×2池化后，每两行两列重新算出一个特征值出来，相当于图像大小减半，因此卷积后的28×28图像经2×2池化后就变为14×14。</p><p>这一层的计算过程是：2×2 单元里的值相加，然后再乘以训练参数w，再加上一个偏置参数b（每一个特征图共享相同的w和b)，然后取sigmoid值（S函数：0-1区间），作为对应的该单元的值。卷积操作与池化的示意图如下：</p><p>这里写图片描述</p><p>（2）参数个数</p><p>S2层由于每个特征图都共享相同的w和b这两个参数，因此需要2×6=12个参数</p><p>（3）连接数</p><p>下采样之后的图像大小为14×14，因此S2层的每个特征图有14×14个神经元，每个池化单元连接数为2×2+1（1为偏置量），因此，该层的连接数为（2×2+1）×14×14×6 = 5880</p><p>3、C3层（卷积层）：16@10×10</p><p>C3层有16个卷积核，卷积模板大小为5×5。</p><p>（1）特征图大小</p><p>与C1层的分析类似，C3层的特征图大小为（14-5+1）×（14-5+1）= 10×10</p><p>（2）参数个数</p><p>需要注意的是，C3与S2并不是全连接而是部分连接，有些是C3连接到S2三层、有些四层、甚至达到6层，通过这种方式提取更多特征，连接的规则如下表所示：</p><p>这里写图片描述</p><p>例如第一列表示C3层的第0个特征图（feature map）只跟S2层的第0、1和2这三个feature maps相连接，计算过程为：用3个卷积模板分别与S2层的3个feature maps进行卷积，然后将卷积的结果相加求和，再加上一个偏置，再取sigmoid得出卷积后对应的feature map了。其它列也是类似（有些是3个卷积模板，有些是4个，有些是6个）。因此，C3层的参数数目为（5×5×3+1）×6 +（5×5×4+1）×9 +5×5×6+1 = 1516</p><p>（3）连接数</p><p>卷积后的特征图大小为10×10，参数数量为1516，因此连接数为1516×10×10= 151600</p><p>4、S4（下采样层，也称池化层）：16@5×5</p><p>（1）特征图大小</p><p>与S2的分析类似，池化单元大小为2×2，因此，该层与C3一样共有16个特征图，每个特征图的大小为5×5。</p><p>（2）参数数量</p><p>与S2的计算类似，所需要参数个数为16×2 = 32</p><p>（3）连接数</p><p>连接数为（2×2+1）×5×5×16 = 2000</p><p>5、C5层（卷积层）：120</p><p>（1）特征图大小</p><p>该层有120个卷积核，每个卷积核的大小仍为5×5，因此有120个特征图。由于S4层的大小为5×5，而该层的卷积核大小也是5×5，因此特征图大小为（5-5+1）×（5-5+1）= 1×1。这样该层就刚好变成了全连接，这只是巧合，如果原始输入的图像比较大，则该层就不是全连接了。</p><p>（2）参数个数</p><p>与前面的分析类似，本层的参数数目为120×（5×5×16+1） = 48120</p><p>（3）连接数</p><p>由于该层的特征图大小刚好为1×1，因此连接数为48120×1×1=48120</p><p>6、F6层（全连接层）：84</p><p>（1）特征图大小</p><p>F6层有84个单元，之所以选这个数字的原因是来自于输出层的设计，对应于一个7×12的比特图，如下图所示，-1表示白色，1表示黑色，这样每个符号的比特图的黑白色就对应于一个编码。</p><p>这里写图片描述</p><p>该层有84个特征图，特征图大小与C5一样都是1×1，与C5层全连接。</p><p>（2）参数个数</p><p>由于是全连接，参数数量为（120+1）×84=10164。跟经典神经网络一样，F6层计算输入向量和权重向量之间的点积，再加上一个偏置，然后将其传递给sigmoid函数得出结果。</p><p>（3）连接数</p><p>由于是全连接，连接数与参数数量一样，也是10164。</p><p>7、OUTPUT层（输出层）：10</p><p>Output层也是全连接层，共有10个节点，分别代表数字0到9。如果第i个节点的值为0，则表示网络识别的结果是数字i。</p><p>（1）特征图大小</p><p>该层采用径向基函数（RBF）的网络连接方式，假设x是上一层的输入，y是RBF的输出，则RBF输出的计算方式是：</p><p>这里写图片描述</p><p>上式中的Wij的值由i的比特图编码确定，i从0到9，j取值从0到7×12-1。RBF输出的值越接近于0，表示当前网络输入的识别结果与字符i越接近。</p><p>（2）参数个数</p><p>由于是全连接，参数个数为84×10=840</p><p>（3）连接数</p><p>由于是全连接，连接数与参数个数一样，也是840</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;手写字体识别模型LeNet5诞生于1994年，是最早的卷积神经网络之一。LeNet5通过巧妙的设计，利用卷积、参数共享、池化等操作提取特征，避免了大量的计算成本，最后再使用全连接神经网络进行分类识别，这个网络也是最近大量神经网络架构的起点。
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>Mysql学习笔记</title>
    <link href="https://wangchenhust.github.io/2020/04/06/Mysql%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    <id>https://wangchenhust.github.io/2020/04/06/Mysql%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</id>
    <published>2020-04-05T17:37:16.532Z</published>
    <updated>2020-04-05T17:37:59.397Z</updated>
    
    <content type="html"><![CDATA[<p>[TOC]</p><h4 id="检索"><a href="#检索" class="headerlink" title="检索"></a><strong>检索</strong></h4><p>检索列</p><ul><li>SELECT name FROM products;  //数据一般将以它在底层表中出现的顺序显示</li><li>SELECT name,age FROM products;</li><li>SELECT * FROM products;检索出名字未知的列</li></ul><p>检索不同行</p><ul><li>SELECT DISTINCT name FROM products;结果没有重复值</li></ul><p>限制结果</p><ul><li>SELECT name FROM products LIMIT 5;不多于5行</li><li>SELECT name FROM products LIMIT 3，4;返回从行3开始的4行 == LIMIT 4 OFFSET 3</li></ul><h4 id="排序检索"><a href="#排序检索" class="headerlink" title="排序检索"></a><strong>排序检索</strong></h4><p>排序数据</p><ul><li>SELECT name FROM products ORDER BY name;</li></ul><p>按多个列排序</p><ul><li>SELECT name, age, sex  FROM products ORDER BY name,age;升序</li></ul><p>按指定方向列排序</p><ul><li>SELECT name, age, sex  FROM products ORDER BY name DESC;降序</li></ul><h4 id="过滤数据"><a href="#过滤数据" class="headerlink" title="过滤数据"></a><strong>过滤数据</strong></h4><h5 id="使用WHERE子句"><a href="#使用WHERE子句" class="headerlink" title="使用WHERE子句"></a><strong>使用WHERE子句</strong></h5><ul><li>SELECT name, age, sex  FROM products WHERE age=18;在同时使用ORDER BY和WHERE子句时，应该让ORDER BY位于WHERE之后，否则将会产生错误。单引号用来限定字符串，与数值比较不需要引号。</li></ul><p>操作符有：=、 &lt;&gt;(!=)、 &gt; 、&lt;、 &gt;=、 &lt;=、 BETWEEN AND</p><ul><li>空值检查：SELECT name, age, sex  FROM products WHERE age IS NULL;</li></ul><h5 id="组合WHERE子句（AND-OR"><a href="#组合WHERE子句（AND-OR" class="headerlink" title="组合WHERE子句（AND /OR)"></a><strong>组合WHERE子句（AND /OR)</strong></h5><ul><li>AND操作符：SELECT name, age, sex  FROM products WHERE age=18 AND sex = m;</li><li>OR操作符： SELECT name, age, sex  FROM products WHERE age=18 OR sex = w;</li><li>计算次序：组合AND和OR带来了一个有趣的问题，SQL（像多数语言一样）在处理OR操作符前，优先处理AND操作符，由于AND在计算次序中优先级更高，操作符被错误地组合了 如：</li></ul><p>SELECT name, age, sex  FROM products WHERE name = w OR age=&gt;18 AND sex = m;</p><p>会先执行 age=&gt;18 AND sex = m再执行 name = w，就不管年龄了。解决方法是加“（）”</p><ul><li>IN操作符（与OR相当）,优点：1）使用长清单时更直观；2）次序更容易管理；3）执行比OR快；4）可以包含其他SELECT语句；</li></ul><p>SELECT name, age, sex  FROM products WHERE age IN (18,20);</p><ul><li>NOT操作符，后跟否定条件，MYSQL中MySQL支持使用NOT对IN、BETWEEN和 EXISTS子句取反，这与多数其他DBMS允许使用NOT对各种条件 取反有很大的差别。</li></ul><p>SELECT name, age, sex  FROM products WHERE age NOT IN (18,20)</p><h5 id="组合查询（UNION"><a href="#组合查询（UNION" class="headerlink" title="组合查询（UNION)"></a><strong>组合查询（UNION)</strong></h5><p>使用情况：在单个查询中从不同的表返回类似结构的数据；对单个表执行多个查询，按单个查询返回数据。</p><p>UNION指示MySQL执行两条SELECT语句，直接在两条语句中间加上UNION。并把输出组合成单个查询结果集。在简单例子中，使用UNION可能比使用WHERE子句更为复杂。但对于更复杂的过滤条件，或者从多个表（而不是单个表）中检索数据 的情形，使用UNION可能会使处理更简单。</p><p><strong>取消重复的行</strong>：UNION从查询结果集中自动去除了重复的行（换句话说，它的行为与单条SELECT语句中使用多个WHERE子句条件一样）。事实上，如果想返回所有匹配行，可使用UNION ALL而不是UNION。</p><p><strong>对组合结果排序</strong>：在用UNION组合查询时，只能使用一条ORDER BY子句，它必须出现在最后一条SELECT语句之后。</p><h5 id="通配符（用来匹配值的一部分的特殊字符）"><a href="#通配符（用来匹配值的一部分的特殊字符）" class="headerlink" title="通配符（用来匹配值的一部分的特殊字符）"></a><strong>通配符（用来匹配值的一部分的特殊字符）</strong></h5><p><strong>LIKE</strong>操作符：指示MySQL 后跟的搜索模式（由字面值、通配符或两者组合构成）利用通配符匹配而不是直接相等匹配进行比较。</p><p>%通配符，表示任何字符出现任意次数，区分大小写  </p><p>SELECT id,name FROM products WHERE name LIKE ‘jet%’;表示jet开头的任意字符,</p><p>SELECT id,name FROM products WHERE name LIKE ‘s%e’;以s开头，e结尾，%还能匹配0个字符但无法匹配NULL</p><p>_ 通配符，用途与%一样，但下划线只匹配单个字符而不是多个字符</p><p>注：通配符搜索的处理一般要比前面讨论的其他搜索所花时间更长，技巧：1）不要过度使用通配符；2）不要把它们用在搜索模式的开始处；3）仔细注意通配符的位置，否则会返回不想要的数据。</p><h5 id="正则表达式REGEXP（匹配文本的特殊的串）"><a href="#正则表达式REGEXP（匹配文本的特殊的串）" class="headerlink" title="正则表达式REGEXP（匹配文本的特殊的串）"></a><strong>正则表达式REGEXP（匹配文本的特殊的串）</strong></h5><ul><li>基本字符匹配：(.)表示匹配任意一个字符,注SELECT id,name FROM products WHERE name REGEXP ‘wang’;与LIKE的区别是：如果被匹配的文本在列值中出现，LIKE将不会找到它，相应的行也不被返回，但是REGEXP会返回</li><li>进行OR匹配（|）：SELECT name, age  FROM products WHERE age REGEXP ‘18|20’ ORDER BY name;</li><li>匹配几个字符之一([ ]): SELECT name, age  FROM products WHERE age REGEXP ‘[123]20’;匹配1或2或3，等同[1|2|3]</li><li>匹配范围([ - ])：SELECT name, age  FROM products WHERE age REGEXP ‘[1-3]20’;</li><li>匹配特殊字符:，必须用\为前导。\-表示查找-，\.表示查找.，\\表示查找\。SELECT name,age  FROM products WHERE name REGEXP ‘\.’ ORDER BY age;</li><li>匹配字符类:可以使用预定义的字符集，称为字符类。</li></ul><p><img src="D:%5Csoftdownload%5COffice%5C%E6%9C%89%E9%81%93%E4%BA%91%5CFile%5Cwangchen_hust@163.com%5C47eb9ead30b942ff97ad64b9a7c44f4a%5Cclipboard.png" alt="img"></p><ul><li>匹配多个实例:</li></ul><p>SELECT name  FROM peoples WHERE name REGEXP ‘\([0-9] wans?\)’ ORDER BY name;匹配TNT (1 wans)或者TNT (5 wan)。?使得s可选，?匹配它前面的任何字符的0次或1次出现</p><p><img src="D:%5Csoftdownload%5COffice%5C%E6%9C%89%E9%81%93%E4%BA%91%5CFile%5Cwangchen_hust@163.com%5C3bdee341b93e41cc8893d57240e51c99%5Cclipboard.png" alt="img"></p><p>SELECT name  FROM peoples WHERE name REGEXP ‘[[:digit:]]{4}’ ORDER BY name;匹配连在一起的4位数字</p><ul><li>定位符(为了匹配特定位置的文本）：</li></ul><p>SELECT name  FROM peoples WHERE name REGEXP ‘^[0-9\.]’ ORDER BY name;找出以一个数（包括以小数点开始的数）开始的所有名字。^在集合中用时表示否定该集合。</p><p><img src="D:%5Csoftdownload%5COffice%5C%E6%9C%89%E9%81%93%E4%BA%91%5CFile%5Cwangchen_hust@163.com%5C3797cf3c86074e41a24d4d8035718b05%5Cclipboard.png" alt="img"></p><p>注意：LIKE和REGEXP 的不同在于，LIKE匹配整个串而REGEXP匹配子串，利用定位 符，通过用^开始每个表达式，用$结束每个表达式，可以使 REGEXP的作用与LIKE一样。</p><h4 id="创建"><a href="#创建" class="headerlink" title="创建"></a><strong>创建</strong></h4><h5 id="创建计算字段"><a href="#创建计算字段" class="headerlink" title="创建计算字段"></a><strong>创建计算字段</strong></h5><p>计算字段并不实际存在于数据库表中。计算字段是运行时在SELECT语句内创建的。只有数据库知道SELECT语句中哪些列是实际的表列，哪些列是计算字段。从客户机（如应用程序）的角度来看，计算 字段的数据是以与其他列的数据相同的方式返回的。在数据库服务器上完成这些操作比在客户机中完成要快得多。</p><ul><li>拼接列(Concat()): SELECT Concat(name, ‘(‘, country, ‘)’) FROM vendors ORDER BY name;把多个串连接起来形成一个较长的串。删除数据右侧多余的空格来整理数据，可以使用MySQL的RTrim()函数来完成；LTrim()去掉左边的空格。</li></ul><p>注意：不同之处：多数DBMS使用+或||来实现拼接， 当把SQL语句转换成 MySQL语句时一定要小心。</p><ul><li>使用别名(AS):SELECT Concat(RTrim(name), ‘(‘, country, ‘)’)  AS rirle FROM vendors ORDER BY name;赋予组合后的列别名</li><li>执行算术计算：SELECT id,nums,price, nums<em>price AS sums FROM orders HWERE index = 2005;表示新创建的表的第4列名称被替换成sums，且数值为nums</em>price。</li></ul><h5 id="函数（函数没有SQL的可移植性强）"><a href="#函数（函数没有SQL的可移植性强）" class="headerlink" title="函数（函数没有SQL的可移植性强）"></a><strong>函数（函数没有SQL的可移植性强）</strong></h5><ul><li>文本处理函数：</li></ul><p><img src="D:%5Csoftdownload%5COffice%5C%E6%9C%89%E9%81%93%E4%BA%91%5CFile%5Cwangchen_hust@163.com%5Cc1e9e0e8509a45829923657728af03f0%5Cclipboard.png" alt="img"></p><p>SOUNDEX是一个将任何文本串转换为描述其语音表示的字母数字模式的算法。SELECT name FROM customers WHERE name = ‘Y.lie’;若实际为Y.lee则无返回，改用SELECT name FROM customers WHERE Soundex(name) = Soundex(‘Y.lie’);就会返回Y.lee。</p><ul><li>日期和时间处理函数：日期必须为 格式yyyy-mm-dd。Date()和Time()都是在MySQL 4.1.1中第一次引入的。</li></ul><p><img src="D:%5Csoftdownload%5COffice%5C%E6%9C%89%E9%81%93%E4%BA%91%5CFile%5Cwangchen_hust@163.com%5Cbd84653f23df447c8820755738e0ff90%5Cclipboard.png" alt="img"></p><ul><li>数值处理函数</li></ul><p><img src="D:%5Csoftdownload%5COffice%5C%E6%9C%89%E9%81%93%E4%BA%91%5CFile%5Cwangchen_hust@163.com%5Cfac8734f7bba4a088cb4f49c5cc51de7%5Cclipboard.png" alt="img"></p><p><strong>聚集函数</strong>：运行在行组上，计算和返回单个值的函数。</p><p><img src="D:%5Csoftdownload%5COffice%5C%E6%9C%89%E9%81%93%E4%BA%91%5CFile%5Cwangchen_hust@163.com%5C4401c1af74ff4b04aff600982fed21c4%5Cclipboard.png" alt="img"></p><p>AVG()、MAX()、MIN()、SUM()函数忽略列值为NULL的行。使用COUNT(*)对表中行的数目进行计数，不管表列中包含的是空值（NULL）还是非空值。</p><p><strong>聚集不同值</strong>（DISYINCT）：（已经被添加到MySQL 5.0.3中。下面所述 内容在MySQL 4.x中不能正常运行。）SELECT AVG(DISTINCT price) AS avgprice FROM products WHERE id = 03;在使用了DISTINCT后，此例子中的avg_price比较高，因为有多个物品具有相同的较低价格，排除它们（相同点被去掉）提升了平均价格。</p><p><strong>组合聚集函数</strong>:SELECT 语句可根据需要包含多个聚集函数:SELECT AVG(price) AS avgprice MAX(price) AS maxprice FROM products</p><h5 id="分组数据（GROUP-BY子句和HAVING子句）"><a href="#分组数据（GROUP-BY子句和HAVING子句）" class="headerlink" title="分组数据（GROUP BY子句和HAVING子句）"></a><strong>分组数据（GROUP BY子句和HAVING子句）</strong></h5><ul><li><strong>创建分组</strong>（在SELECT语句的<strong>GROUP BY</strong>子句中建立的）</li></ul><p>SELECT COUNT(*) AS num_prods FROM products GROUP BY vend_id ;GROUP BY子句指示按vend_id排序并分组数据,GROUP BY子句指示MySQL分组数据，然后对每个组而不是整个结果集进行聚集。</p><p><em>规定：</em>1）GROUP BY子句可以包含任意数目的列；2）如果在GROUP BY子句中嵌套了分组，数据将在最后规定的分组上 进行汇总；3）每个列都必须是检索列或有效的表达式 （但不能是聚集函数）；4）如果分组列中具有NULL值，则NULL将作为一个分组返回；5）必须出现在WHERE子句之后，ORDER BY子句之前；</p><ul><li><strong>过滤分组HAVING</strong></li></ul><p><em>区别</em>：WHERE过滤指定的是行而不是分组，没有分组的概念。HAVING非常类似于WHERE，过滤分组，且支持所有WHERE操作符。可以理解为WHERE在数据分组前进行过滤，HAVING在数据分组后进行过滤。</p><p>SELECT id, COUNT(<em>) AS orders FROM orders GROUP BY id HAVING COUNT(</em>)&gt;=2;</p><ul><li><strong>分组和排序</strong>（一般在使用GROUP BY子句时，应该也给出ORDER BY子句，不要仅依赖GROUP BY排序数据）</li></ul><p><img src="D:%5Csoftdownload%5COffice%5C%E6%9C%89%E9%81%93%E4%BA%91%5CFile%5Cwangchen_hust@163.com%5Cad7de98658c04f8ea981b04f496f4ca6%5Cclipboard.png" alt="img"></p><ul><li><strong>SELECT子句顺序</strong></li></ul><p><img src="D:%5Csoftdownload%5COffice%5C%E6%9C%89%E9%81%93%E4%BA%91%5CFile%5Cwangchen_hust@163.com%5Ca3d49a9b65c242d993b290921065cba2%5Cclipboard.png" alt="img"></p><h5 id="子查询"><a href="#子查询" class="headerlink" title="子查询"></a><strong>子查询</strong></h5><p>即嵌套在其他查询中的查询，MySQL 4.1引入了对子查询的支持。</p><ul><li><strong>利用子查询进行过滤</strong></li></ul><p>在SELECT语句中，子查询总是从内向外处理。在WHERE子句中使用子查询能够编写出功能很强并且很灵活的</p><p>SQL语句。虽然子查询一般与IN操作符结合使用，但也可以用于测试等于（=）、 不等于（&lt;&gt;）等。如：</p><p>SELECT name,contact FROM customers WHERE id IN(SELECT id FROM orders WHERE order_num IN(5,7))</p><ul><li><strong>作为计算字段使用子查询</strong></li></ul><p>SELECT id , ( SELECT COUNT(*) FROM orders WHERE  orders.id = customers.id)) AS orders FROM customers ORDER BY name;表示假如需要显示customers表中每个客户的订单总数。订单与相应的客户ID存储在orders表中</p><p>注：相关子查询：涉及外部查询的子查询。任何时候只要列名可能有多义性，就必须使用这种语法（表名和列名由一个句点分隔），否则返回错误。</p><h4 id="联结表"><a href="#联结表" class="headerlink" title="联结表"></a><strong>联结表</strong></h4><p><strong>关系表</strong>的设计就是要保证把信息分解成多个表，一类数据 一个表。各表通过某些常用的值（即关系设计中的关系）互相关联。</p><p><strong>联结</strong>是一种机制，用来在一条SELECT语句中关联表，将存储在多个表中的数据检索出来。</p><h5 id="创建联结"><a href="#创建联结" class="headerlink" title="创建联结"></a><strong>创建联结</strong></h5><p>规定要联结的所有表以及它们如何关联。WHERE子句作为过滤条件，它只包含那些匹配给定条件（这里是联结条件）的行。没有WHERE子句，第一个表中的每个行将与第二个表中的每个行配对，而不管它们逻辑上是否可以配在一起。应该保证所有联结都有WHERE子句。</p><p>SELECT v_name,p_name,p_price FROM vendors,products WHERE vendors.id=products.id ORDER BY v_name,p_name;</p><p><strong>内部联结</strong>(即等值联结）SELECT v_name,p_name,p_price FROM vendors INNER JOIN products ON vendors.id=products.id </p><p><strong>联结多个表</strong>:SELECT v_name,p_name,p_price,nums FROM vendors,products,a WHERE vendors.id=products.id AND num=9;不要联结 必要的表。联结的表越多，性能下降越厉害。</p><p>注：联结与子查询有时可以表达同一种功能。</p><h5 id="创建高级联结"><a href="#创建高级联结" class="headerlink" title="创建高级联结"></a><strong>创建高级联结</strong></h5><p>表别名不仅能用于WHERE子句，它还可以用于SELECT的列表、ORDER BY子句以及语句的其他部分。原因：在单条SELECT语句中不止一次引用相同的表，简便表达。</p><ul><li><strong>自联结</strong></li></ul><p>SELECT p1.id,p1.name FROM products AS p1,products AS p2 WHERE p1.v_id =p2.v_id AND p2.id = ‘TNT’; products表在 FROM子句中出现了两次，为解决对products的引用二义性，将两次出现的products分别命名。</p><p>自联结通常作为外部语句用来替代 从相同表中检索数据时使用的子查询语句，且速度快。</p><ul><li><strong>自然连联结</strong></li></ul><p>标准的联结（前一章中介绍的内部联结）返回所有数据，甚 至相同的列多次出现。自然联结排除多次出现，使每个列只返回一次。这一 般是通过对表使用通配符（SELECT *），对所有其他表的列使用明确的子 集来完成的。</p><ul><li><strong>外部联结</strong></li></ul><p>但有时候会需要包含没有关联行的那些行。</p><p>SELECT customers.id ,orders.nums FROM customers RIGHT OUTER JOIN orders ON orders.id = customers.id</p><h5 id="全文本搜索"><a href="#全文本搜索" class="headerlink" title="全文本搜索"></a><strong>全文本搜索</strong></h5><p>两个最常使用的引擎为MyISAM和InnoDB， 前者支持全文本搜索，而后者不支持。在使用全文本搜索时，MySQL不需要分别查看每个行，不需要分别分析和处理 每个词。MySQL创建指定列中各词的一个索引，搜索可以针对这些词进行。</p><p>LIKE与REGEXP的限制：1）通配符和正则表达式匹配通常要求MySQL尝试匹配表中的所有行，耗时长性能低；2）使用通配符和正则表达式匹配，很难明确地控制匹配什么和不匹配什么；3）个特殊词的搜索将会返回包含该词的所有行，而不区分包含单个匹配的行和包含多个匹配的行，不灵活。</p><ul><li>启用</li></ul><p>CREATE TABLE语句接受FULLTEXT子句，它给出被索引列的一个逗号分隔的列表。MySQL自动维护,在增加、更新或删除行时，索引随之自动更新。</p><p>CREAT TABLE productnotes</p><p>(note_id  int      NOT NULL,</p><p> prod_id  char(10) NOT NULL,</p><p> note _text text   NULL,</p><p> PRIMARY KEY(note_id),</p><p>FULLTEXT(note_text))ENGINE=MyISAM;   MySQL根据子句FULLTEXT(note_text)的指示对它进行索引</p><ul><li>进行</li></ul><p>在索引之后，使用两个函数Match()和Against()执行全文本搜索，其中Match()指定被搜索的列，Against()指定要使用的搜索表达式。递给Match()的值必须与 FULLTEXT()定义中的相同。不区分大小写。</p><p>SELECT note_text FROM productnotes WHERE Match(note_texts) Against (‘rabbit’);</p><p>注：全文本搜索的一 个重要部分就是对结果排序。具有较高等级的行先返回。比如排在第3位的rabbit比排在20位的等级高</p><ul><li>查询扩展（只用于MySQL版本4.1.1或更高级的版本）</li></ul><p>用途：你想找出所有提到anvils的注释。只有一个注释包含词anvils， 但你还想找出可能与你的搜索有关的所有其他行。</p><p>MySQL对数据和索引进行两遍扫描来完成搜索：1）首先，进行一个基本的全文本搜索，找出与搜索条件匹配的所有行；2）其次，MySQL检查这些匹配行并选择所有有用的词；3）再其次，MySQL再次进行全文本搜索，这次不仅使用原来的条件， 而且还使用所有有用的词。</p><p>SELECT note_text FROM productnotes WHERE Match(note_texts) Against (‘rabbit’ WITH QUERY EXPANSION);</p><p>表中的行越多，使用查询扩展返回的结果越好。</p><ul><li>布尔文本搜索(即使没有定义 FULLTEXT索引也可使用，索引缓慢)</li></ul><p>SELECT note_text FROM productnotes WHERE Match(note_texts) Against (‘rabbit’ IN BOLLEN MODE);若没有指定布尔操作符，则其结果与没有指定布尔方式的结果相同。</p><p>SELECT note_text FROM productnotes WHERE Match(note_texts) Against (‘rabbit -rope<em>‘ IN BOLLEN MODE);这一次仍然匹配词rabbit，但-rope*明确地指示MySQL排除包含rope</em>(任何以rope开始的词，包括 ropes的行.</p><p><img src="D:%5Csoftdownload%5COffice%5C%E6%9C%89%E9%81%93%E4%BA%91%5CFile%5Cwangchen_hust@163.com%5Cc4fd54d31e8348e881243cd3cf38881c%5Cclipboard.png" alt="img"></p><p>全文本搜索的使用说明：1）在索引全文本数据时，短词（3及3个以下字符）被忽略且从索引中排除；2）MySQL带有一个内建的非用词（stopword）列表，这些词在索引全文本数据时总是被忽略。如果需要，可以覆盖这个列表；3）许多词出现的频率很高，搜索它们没有用处。 MySQL规定了一条50%规则，如果一个词出现在50%以上的行中，则将它作为一个非用词忽略。50%规则不用于IN BOOLEAN MODE。4）如果表中的行数少于3行，则全文本搜索不返回结果；5）忽略词中的单引号。例如，don’t索引为dont；6）不具有词分隔符（包括日语和汉语）的语言不能恰当地返回全文本搜索结果；6）仅在MyISAM数据库引擎中支持全文本搜索；7）MySQL全文本搜索现在还 不支持邻近操作符。</p><h4 id="改动数据-表"><a href="#改动数据-表" class="headerlink" title="改动数据/表"></a><strong>改动数据/表</strong></h4><h5 id="插入数据INSERT"><a href="#插入数据INSERT" class="headerlink" title="插入数据INSERT"></a><strong>插入数据INSERT</strong></h5><ul><li>插入单行</li></ul><p>INSERT INTO table(……) VALUES(……)，给出列名与对应的值，则没有值的列不需要写。</p><ul><li>插入多行</li></ul><p>可以使用多条INSERT语句，甚至一次提交它们，每条语句用一个分号结束，如：INSERT INTO table(……) VALUES(……)；INSERT INTO table(……) VALUES(……)；或者，只要每条INSERT语句中的列名（和次序）相同，每组值用一对圆括号括起来， 用逗号分隔，即INSERT INTO table(……)  VALUES(……)(……)</p><ul><li>插入检索出的数据</li></ul><p>INSERT INTO table(id1,id2)  SELECT id1,id2 FROM custnew;不一定要求列名匹配,Mysql使用的是列的位置。</p><h5 id="更新数据UPDATE"><a href="#更新数据UPDATE" class="headerlink" title="更新数据UPDATE"></a><strong>更新数据UPDATE</strong></h5><p>UPDATE customers SET cust_email = ‘e@.com’ WHERE id=105; UPDATE语句总是以要更新的表的名字开始。在此例子中，要更新的表的名字为customers。SET命令用来将新值赋给被更新的列,UPDATE语句以WHERE子句结束，它告诉MySQL更新哪一行。在更新多个列时，只需要使用单个SET命令，每个“列=值”对之间用逗号分隔（最后一列之后不用逗号）。</p><p>如果用UPDATE语句更新多行，并且在更新这些行中的一行或多行时出一个现错误，则整个UPDATE操作被取消。如果即使是发生错误，也继续进行更新，可使用IGNORE关键字，UPDATE IGNORE customers…</p><p>为了删除某个列的值，可设置它为NULL。UPDATE customers SET cust_email =NULL WHERE id=105;</p><h5 id="删除数据DELETE"><a href="#删除数据DELETE" class="headerlink" title="删除数据DELETE"></a><strong>删除数据DELETE</strong></h5><p>DELETE FROM customers WHERE id=105;DELETE FROM要求指定从中删除数据的表名,WHERE子句过滤要删除的行。</p><p>DELETE不需要列名或通配符。DELETE删除整行而不是删除列。且DELETE不删除表本身。删除列用UPDATE。</p><p>如果想从表中删除所有行，不要使用DELETE。 可使用TRUNCATE TABLE语句，速度更快（TRUNCATE实际是删除原来的表并重新创建一个表，而不是逐行删除表中的数据）。MySQL没有撤销（undo）按钮。应该非常小心地使用UPDATE和DELETE，以免更新或删除了错误的数据。尽量用WHERE。</p><h5 id="创建表"><a href="#创建表" class="headerlink" title="创建表"></a><strong>创建表</strong></h5><p>创建表的两种方式：</p><p>使用具有交互式创建和管理表的工具； </p><p>表也可以直接用MySQL语句操纵。</p><ul><li>创建：新表的名字，在关键字CREATE TABLE之后给出； 表列的名字和定义，用逗号分隔。</li></ul><p>CREAT TABLE customers(</p><p>id   int       NOT NULL AUTO_INCREMENT,##AUTO_INCREMENT告诉MySQL，本列每当增加一行时自动增量（+1）。每次</p><p>执行一个INSERT操作时，MySQL自动对该列增量。每个表只允许一个AUTO_INCREMENT列，而且它必须被索引（成为主键）。</p><p>name caher(50) NOT NULL DEFAULT m,##DEFAULT指定默认值，MySQL不允许使用函 数作为默认值，它只支持常量。</p><p>PRIMARY KEY(id)##主键需唯一，若是组合键，则应该加圆括号，逗号分隔。键可以在创建表时定义，或在创建表之后定义</p><p>)ENGINE=InnoDB;</p><p>每个表列或者是NULL列，或者是NOT NULL列，这种状态在创建时由表的定义规定。含有关键字NOT NULL的列表，如果试图插入没有值的列，将返回错误。</p><ul><li>引擎</li></ul><p>与其他DBMS一样，MySQL有一个具体管理和处理数据的内部引擎。在你使用CREATE TABLE语句时，该引擎具体创建表，而在你使用SELECT 语句或进行其他数据库处理时，该引擎在内部处理你的请求。多数时候， 此引擎都隐藏在DBMS内，不需要过多关注它。 </p><p>但MySQL与其他DBMS不一样，它具有多种引擎。它打包多个引擎，这些引擎都隐藏在MySQL服务器内，全都能执行CREATE TABLE和SELECT 等命令。为不同的任务选择正确的引擎能获得良好的功能和灵活性。引擎类型可以混用。</p><p>缺点：外键（用于强制实施引用完整性）不能跨引擎，即使用一个引擎的表不能引用具有使用不同引擎的表的外键。</p><ul><li><ul><li>InnoDB是一个可靠的事务处理引擎，它不支持全文 本搜索；</li><li>MEMORY在功能等同于MyISAM，但由于数据存储在内存（不是磁盘） 中，速度很快（特别适合于临时表）；</li><li>MyISAM是一个性能极高的引擎，它支持全文本搜索， 但不支持事务处理</li></ul></li><li><p>更新表</p></li></ul><p>为更新表定义，可使用ALTER TABLE语句。但是，理想状态下，当表中存储数据以后，该表就不应该再被更新。ALTER TABLE之后给出要更改的表名，和所做更改的列。</p><p>ALTER TABLE vendors ADD phone CHAR(10);</p><p>ALTER TABLE vendors DROP phone ;</p><p>使用ALTER TABLE要极为小心，应该在进行改动前做一个完整的备份（模式和数据的备份）。数据库表的更改不能撤销,如果增加了不需要的列，可能不能删除它们。类似地，如果删除了不应该删除的列，可能会丢失该列中的所有数据。</p><ul><li>删除表</li></ul><p>DROP TABLE customers2;</p><ul><li>重命名</li></ul><p>RENAME TABLE back1 TO customers1,back2 TO customers2;</p><h4 id="视图"><a href="#视图" class="headerlink" title="视图"></a><strong>视图</strong></h4><p>MySQL 5添加了对视图的支持。视图是虚拟的表。与包含数据的表不一样，视图只包含使用时动态检索数据的查询。视图仅仅是用来查看存储在别处的数据的一种设施。视图本身不包含数据。视图主要用来检索数据。例子：</p><p>SELECT name,contact FROM customers orders,orderitems WHERE customers.id=orders.id AND p_id = ‘105’;假如可以把整个查询包装成一个名为productcustomers的虚拟表,，则可以如下轻松地检索出相同的数据，如下：</p><p>SELECT name,contact FROM productcustomers WHERE p_id = ‘105’;这就是视图的作用。productcustomers是一个视图，作为视图，它不包含表中应该有的任何列或数据，它包含的是一个SQL查询。</p><p><strong>意义</strong>：1）重用SQL语句；2）使用表的组成部分而不是整个表；3）保护数据；4）更改数据格式和表示，视图可返回与底层表的表示和格式不同的数据。</p><p><strong>规则和限制</strong> </p><p> 与表一样，视图必须唯一命名（不能给视图取与别的视图或表相同的名字）。</p><p> 对于可以创建的视图数目没有限制。 </p><p> 为了创建视图，必须具有足够的访问权限。这些限制通常由数据库管理人员授予。</p><p> 视图可以嵌套，即可以利用从其他视图中检索数据的查询来构造一个视图。</p><p> ORDER BY可以用在视图中，但如果从该视图检索数据SELECT中也含有ORDER BY，那么该视图中的ORDER BY将被覆盖。</p><p> 视图不能索引，也不能有关联的触发器或默认值。 </p><p> 视图可以和表一起使用。例如，编写一条联结表和视图的SELECT 语句。</p><p><strong>使用视图步骤</strong>：</p><p> 视图用CREATE VIEW语句来创建。 CREATE VIEW table1 AS SELECT………………</p><p> 使用SHOW CREATE VIEW viewname；来查看创建视图的语句；</p><p> 用DROP删除视图，其语法为DROP VIEW viewname;</p><p> 更新视图时，可以先用DROP再用CREATE，也可以直接用CREATE OR REPLACE VIEW。如果要更新的视图不存在，则第2条更新语句会创 建一个视图；如果要更新的视图存在，则第2条更新语句会替换原有视图。</p><p>WHERE子句：如果从视图检索数据时使用了一条 WHERE子句，则两组子句（一组在视图中，另一组是传递给视 图的）将自动组合。</p><p>如果视图定义中有以下操作，则不能进行视图的更新：分组（使用GROUP BY和HAVING）；联结；子查询；并；聚集函数；DISTINCT;导出（计算）列。–是注释。</p><h4 id="存储过程"><a href="#存储过程" class="headerlink" title="存储过程"></a><strong>存储过程</strong></h4><h5 id="执行和创建"><a href="#执行和创建" class="headerlink" title="执行和创建"></a><strong>执行和创建</strong></h5><p>MySQL 5添加了对存储过程的支持。经常会有一个完整的操作需要多条语句才能完成。存储过程简单来说，就是为以后的使用而保存的一条或多条MySQL语句的集合。可将其视为批文件，虽然它们的作用不仅限于批处理。优点：简单、安全、高性能。</p><p>具体作用：</p><p> 通过把处理封装在容易使用的单元中，简化复杂的操作。</p><p> 由于不要求反复建立一系列处理步骤，这保证了数据的完整性。 如果所有开发人员和应用程序都使用同一（试验和测试）存储过程，则所使用的代码都是相同的。 这一点的延伸就是防止错误。需要执行的步骤越多，出错的可能 性就越大。</p><p> 简化对变动的管理。如果表名、列名或业务逻辑（或别的内容） 有变化，只需要更改存储过程的代码。使用它的人员甚至不需要 知道这些变化。 这一点的延伸就是安全性。通过存储过程限制对基础数据的访问减少了数据讹误（无意识的或别的原因所导致的数据讹误）的机会。</p><p>  提高性能。因为使用存储过程比使用单独的SQL语句要快。 </p><p> 存在一些只能用在单个请求中的MySQL元素和特性，存储过程可以使用它们来编写功能更强更灵活的代码。</p><ul><li><strong>执行存储过程CALL</strong></li></ul><p>MySQL称存储过程的执行为调用,CALL接受存储过程的名字以及需要传递给它的任意参数。</p><p>CALL productpricing(@pricelow,@pricehigh);执行名为productpricing的存储过程，计算并返回产品的最低、最高价格。</p><ul><li><strong>创建存储过程</strong></li></ul><p>CREATE PROCEDURE productpricing() BEGIN SELECT Avg(price) AS priceaverage FROM products END;如果存储过程接受参数，它们将在()中列举出来。存储过程实际上是一种函数。BEGIN和END语句用来限定存储过程体。</p><p>CALL  productpricing();上面无返回，这句才是使用，有返回数据。</p><ul><li><strong>删除存储过程</strong></li></ul><p>DROP PROCEDURE productpricing;无()</p><ul><li><strong>使用参数</strong></li></ul><p>变量（variable）：内存中一个特定的位置，用来临时存储数据。所有MySQL变量都必须以@开始。</p><p>CREATE PROCEDURE productpricing(OUT pl DECIMAL(8,2))…… 每个参数必须具有指定的类。MySQL支持IN（传递给存储过程）、OUT（从存储过程传出）和INOUT（对存储过程传入和传出）类型的参数。</p><p>参数的数据类型：存储过程的参数允许的数据类型与表中使用的数据类型相同。</p><p>CALL  productpricing((@pricelow,@pricehigh);</p><p>SELECT  @pricehigh;显示</p><ul><li>检查存储过程</li></ul><p>SHOW CREATE PROCEDURE ordertotal;显示</p><p>SHOW PROCEDURE STATUS;获得包括何时、由谁创建等详细信息的存储过程列表。为限制其输出，可使用LIKE指定一个过滤模式SHOW PROCEDURE STATUS LIKE ‘ordertotal’;</p><h5 id="游标"><a href="#游标" class="headerlink" title="游标"></a><strong>游标</strong></h5><p>MySQL 5添加了对游标的支持。MySQL检索操作返回一组称为结果集的行。有时，需要在检索出来的行中前进或后退一行或多行。这就是使用游标的原因。游标（cursor）是一个存储在MySQL服务器上的数据库查询，它不是一条SELECT语句，而是被该语句检索出来的结果集。在存储了游标之后，应用程序可以根据需要滚动或浏览其中的数据。要用于交互式应用，其中用户需要滚动屏幕上的数据，并对数据进行浏览或做出更改。游标只能用于 存储过程（和函数）。</p><ul><li>步骤：</li></ul><p> 在能够使用游标前，必须声明（定义）它。</p><p> 一旦声明后，必须打开游标以供使用。这个过程用前面定义的 SELECT语句把数据实际检索出来。</p><p> 对于填有数据的游标，根据需要取出（检索）各行。 </p><p> 在结束游标使用时，必须关闭游标。</p><ul><li>创建游标DECLARE</li></ul><p>CREATE PROCEDURE processorders() BEGIN DECLEAR ordernumbers CURSOR FOR SELECT order_num FROM orders END;DECLARE语句用来定义和命 名游标，这里为ordernumbers，理完成后，游标就消失。</p><ul><li>打开和关闭游标（OPEN CURSOR/CLOSE)</li></ul><p>OPEN ordernumbers;使用声明过的游标不需要再次声明，用OPEN语句打开它就可以了</p><p>CLOSE ordernumbers;</p><ul><li>使用游标数据FETCH</li></ul><p>在一个游标被打开后，可以使用FETCH语句分别访问它的每一行。</p><h4 id="触发器"><a href="#触发器" class="headerlink" title="触发器"></a><strong>触发器</strong></h4><p>对触发器的支持是在MySQL 5中增加的。想要某条语句（或某些语句）在事件发生时自动执行，就采用触发器。触发器是MySQL响应以下任意语句（DELETE 、INSERT、 UPDATE）而自动执行的一条MySQL语句（或位于BEGIN和END语句之间的一组语句）。仅支持表 ：只有表才支持触发器，视图不支持（临时表也不支持）。</p><ul><li>创建CREATE TRIGGER</li></ul><p>4条信息：唯一的触发器名； 触发器关联的表； 触发器应该响应的活动； 触发器何时执行（处理之前或之后）</p><p>CREATE TRIGGER newproduct AFTER INSERT ON products FOR EACH ROW SELECT ‘product added’;为了测试这个触发器，使用INSERT语句添加一行或多行到products中，你将看到对每个成功的插入，显示Product added消息。</p><ul><li>删除触发器DROP TRIGGER</li></ul><p>DROP TRIGGER newproduct;触发器不能更新或覆盖。为了修改一个触发器，必须先删除它， 然后再重新创建。</p><ul><li>使用触发器</li></ul><p>INSERT触发器</p><p>在INSERT触发器代码内，可引用一个名为NEW的虚拟表，访问被插入的行；</p><p>BEFORE INSERT触发器中，NEW中的值也可以被更新（允许更改 被插入的值）；</p><p>对于AUTO_INCREMENT列，NEW在INSERT执行之前包含0，在INSERT 执行之后包含新的自动生成值;</p><p>将BEFORE用于数据验证和净化（目的是保证插入表中的数据确实是需要的数据）。</p><p>DELETE触发器</p><p>在DELETE触发器代码内，你可以引用一个名为OLD的虚拟表，访问被删除的行;</p><p>OLD中的值全都是只读的，不能更新。</p><p>UPDATE触发器</p><p>在UPDATE触发器代码中，你可以引用一个名为OLD的虚拟表访问 以前（UPDATE语句前）的值，引用一个名为NEW的虚拟表访问新 更新的值；</p><p>在BEFORE UPDATE触发器中，NEW中的值可能也被更新（允许更改将要用于UPDATE语句中的值）；</p><p>OLD中的值全都是只读的，不能更新。</p><h4 id="事务处理"><a href="#事务处理" class="headerlink" title="事务处理"></a><strong>事务处理</strong></h4><p>MyISAM和InnoDB是两种最常使用的引擎。前者不支持明确的事务处理管理，而后者支持。</p><p>事务处理（transaction processing）可以用来维护数据库的完整性，它保证成批的MySQL操作要么完全执行，要么完全不执行。</p><p>术语：</p><p> 事务（transaction）指一组SQL语句；</p><p> 回退（rollback）指撤销指定SQL语句的过程； </p><p> 提交（commit）指将未存储的SQL语句结果写入数据库表； </p><p> 保留点（savepoint）指事务处理中设置的临时占位符（placeholder），你可以对它发布回退（与回退整个事务处理不同）。</p><p>控制事务处理</p><p>管理事务处理的关键在于将SQL语句组分解为逻辑块，并明确规定数据何时应该回退，何时不应该回退。</p><p>START TRANSACTION;</p><ul><li>回退（撤销）ROLLBACK</li></ul><p>ROLLBACK只能在一个事务处理内使用（在执行一条START TRANSACTION命令之后）</p><ul><li>提交COMMIT</li></ul><p>在事务处理块中，提交不会隐含地进行。为进行明确的提交，使用COMMIT语句。当COMMIT或ROLLBACK语句执行后，事务会自动关闭（将来的更改会隐含提交）。</p><ul><li>保留点</li></ul><p>为了支持回退部分事务处理，必须能在事务处理块中合适的位置放置占位符。这样，如果需要回退，可以回退到某个占位符。</p><p>创建占位符：SAVEPOINT deletel;</p><p>ROLLBACK TO deletel;每个保留点都取标识它的唯一名字，以便在回退时，MySQL知道要回退到何处。</p><p>释放保留点：RELEASE SAVEPOINT</p><ul><li>更改默认的提交行为</li></ul><p>SET autocommit=0;为指示MySQL不自动提交更改。autocommit标志是针对每个连接而不是服务器的。</p><p><strong>处理不同字符集和语言</strong></p><p>字符集和校对顺序：使用何种字符集和校对的决定在服务器、数据库和表级进行</p><p>SHOW CHARACTER SET;显示所有可用的字符集以及每个字符集的描述和默认校对</p><p>SHOW COLLATION;显示所有可用的校对，以及它们适用的字符集</p><p>校对在对用ORDER BY子句检索出来的数据排序时起重要的作用。</p><p>得注意的是，如果绝对需要，串可以在字符集之间进行转换。为此，使用Cast()或Convert()函数。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;[TOC]&lt;/p&gt;
&lt;h4 id=&quot;检索&quot;&gt;&lt;a href=&quot;#检索&quot; class=&quot;headerlink&quot; title=&quot;检索&quot;&gt;&lt;/a&gt;&lt;strong&gt;检索&lt;/strong&gt;&lt;/h4&gt;&lt;p&gt;检索列&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;SELECT name FROM produc
      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>Python学习/爬虫框架</title>
    <link href="https://wangchenhust.github.io/2020/02/18/Python%E5%AD%A6%E4%B9%A0/%E7%88%AC%E8%99%AB%E6%A1%86%E6%9E%B6/"/>
    <id>https://wangchenhust.github.io/2020/02/18/Python%E5%AD%A6%E4%B9%A0/%E7%88%AC%E8%99%AB%E6%A1%86%E6%9E%B6/</id>
    <published>2020-02-18T07:56:01.129Z</published>
    <updated>2020-02-18T08:38:23.537Z</updated>
    
    <content type="html"><![CDATA[<p><strong>Scrapy爬虫框架</strong></p><p>​        爬虫框架是实现爬虫功能的一个软件结构和功能组件集合；是一个半成品，能够帮助用户实现专业网络爬虫。</p><p>​        Scarpy是一个功能非常强大的爬虫框架。它不仅能便捷地构建request，还有强大的 selector 能够方便地解析 response，可以将爬虫工程化、模块化。<a id="more"></a></p><img src="C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20200216132325542.png" alt="image-20200216132325542" style="zoom: 50%;" /><p>​        三条主要的数据流，ENGINE、DOWNLOADER、SCHEDULER在python中有现成模块，用户只需要对<u>SPIDER、ITEM PIPELINES</u>进行配置。</p><p><strong>组成</strong>：</p><ul><li><strong>引擎（Engine）</strong>：控制所有模块之间的数据流；根据条件触发事件（框架核心。</li><li><strong>下载器（Downloader）</strong>：根据请求下载网页内容，并将网页内容返回给引擎（Scrapy下载器是建立在twisted这个高效的异步模型上的）。</li><li><strong>调度器（Sceduler）</strong>：对所有爬取请求进行调度管理，接受引擎发过来的请求，压入队列中，并在引擎再次请求的时候返回。</li><li><strong>下载器中间件（Downloder Middleware）</strong>:位于引擎和下载器之间，可以修改、丢弃、新增请求或响应，目的是实施Engine、Sceduler和Downloader之间的用户可配置的控制。（反爬措施可以在这里加入）</li><li><strong>爬虫（Spider）</strong>：解析Downloader返回的响应；产生爬取项（即提取item）；产生额外的爬取请求。每个Spider处理一个（一些）特定网站。</li><li><strong>项目管道（Item Pipelines）</strong>：以流水线方式处理Spider产生的爬取项；由一组操作顺序组成，每个操作是一个Item Pipelines类型；可能的操作包括：清理、验证和查重爬取项中的HTML数据，将数据存储到数据库。</li><li><strong>爬虫中间件（Spider Middleware）</strong>：位于引擎和爬虫之间，主要工作是修改、丢弃、新增请求或爬取项，目的是对请求和爬取项的再处理。</li></ul><p><strong>Scrapy命令行</strong>：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&gt;scrapy&lt;command&gt;[options][args]</span><br></pre></td></tr></table></figure><p>命令行更容易自动化，适合脚本控制，给程序员使用</p><p><a href="https://www.cnblogs.com/zengsf/p/10039106.html" target="_blank" rel="noopener">常用命令</a>：</p><table><thead><tr><th>命令</th><th>说明</th><th>格式</th></tr></thead><tbody><tr><td>startproject</td><td>创建一个新工程</td><td>scrapy startproject <name>[dir]</td></tr><tr><td>genspider</td><td>创建一个爬虫</td><td>scrapy genspider [options]<name><domain></td></tr><tr><td>settings</td><td>获得爬虫配置的信息</td><td>scrapy settings[options]</td></tr><tr><td>crawl</td><td>运行一个爬虫</td><td>scrapy crawl<spider></td></tr><tr><td>list</td><td>列出工程中所有爬虫</td><td>scrapy list</td></tr><tr><td>shell</td><td>启动URL调试命令行</td><td>scrapy shell[url]</td></tr></tbody></table><p><strong>Scrapy爬虫的使用步骤</strong></p><ul><li><p>step1：创建一个工程和Spider模板</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&gt;scrapy startproject Projectname</span><br><span class="line">&gt;cd Projectname</span><br><span class="line">&gt;scrapy genspider example example.com</span><br><span class="line">进一步修改spiders&#x2F;example.py文件</span><br></pre></td></tr></table></figure><p>示例工程（python123demo）目录详解：</p><img src="C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20200216171046494.png" alt="image-20200216171046494" style="zoom: 50%;" /></li><li><p>step2：编写Spider</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">配置stocks.py文件</span><br><span class="line">修改对返回页面的处理</span><br><span class="line">修改对新增URL爬取请求处理</span><br></pre></td></tr></table></figure></li><li><p>step3：编写Item Piplline</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">配置pipeline.py文件</span><br><span class="line">定义对爬取项（Scraped Item）的处理类</span><br><span class="line">配置ITEM_PIPELINE选项</span><br></pre></td></tr></table></figure></li><li><p>step4：优化配置策略（修改settings.py)</p></li></ul><p>三个主要类</p><ul><li><strong>Request类</strong></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">scrapy</span>.<span class="title">http</span>.<span class="title">Request</span><span class="params">()</span></span></span><br></pre></td></tr></table></figure><p>Request对象表示一个HTTP请求，由Spider生成，由Downloader执行。</p><table><thead><tr><th>属性或方法</th><th>说明</th></tr></thead><tbody><tr><td>.url</td><td>Request对应的请求URL地址</td></tr><tr><td>.method</td><td>对应的请求方法，’GET’ ‘POST’等</td></tr><tr><td>.headers</td><td>字典类型风格的请求头</td></tr><tr><td>.body</td><td>请求内容主体，字符串类型</td></tr><tr><td>.meta</td><td>用户添加的扩展信息，在Scrapy内部模块间传递信息使用</td></tr><tr><td>.copy()</td><td>复制该请求</td></tr></tbody></table><ul><li><strong>Response类</strong></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">scrapy</span>.<span class="title">http</span>.<span class="title">Response</span><span class="params">()</span></span></span><br></pre></td></tr></table></figure><p>Response对象表示一个HTTP响应，由Downloader生成，由Spider处理。</p><table><thead><tr><th>属性或方法</th><th>说明</th></tr></thead><tbody><tr><td>.url</td><td>Response对应的URL地址</td></tr><tr><td>.status</td><td>HTTP状态码，默认是200</td></tr><tr><td>.headers</td><td>Response对应的头部信息</td></tr><tr><td>.body</td><td>Response对应的内容信息，字符串类型</td></tr><tr><td>.flags</td><td>一组标记</td></tr><tr><td>.request</td><td>产生Response类型对应的Request对象</td></tr><tr><td>.copy()</td><td>复制该响应</td></tr></tbody></table><ul><li><strong>Item类</strong></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">scrapy</span>.<span class="title">item</span>.<span class="title">Item</span><span class="params">()</span></span></span><br></pre></td></tr></table></figure><p>​        Item对象表示一个从HTML页面中提取的信息内容，由Spider生成，由Item Pipeline处理，Item类似字典类型，可以按照字典类型操作。</p><p><strong>提取信息方法</strong></p><p>Scrapy爬虫支持多种HTML信息提取方法：<br>• Beautiful Soup<br>• lxml<br>• re<br>• XPath Selector<br>• CSS Selector</p><p><strong>requests与Scrapy比较</strong></p><p>相同点：</p><ol><li>都可以进行页面请求和爬取；</li><li>可用性好，文档丰富；</li><li>都没有处理JS、提交表单、应对验证码等功能。</li></ol><p>不同点</p><table><thead><tr><th>Requests</th><th>Scrapy</th></tr></thead><tbody><tr><td>页面级爬虫</td><td>网站级爬虫</td></tr><tr><td>功能库</td><td>框架</td></tr><tr><td>并发性考虑不足，性能较差</td><td>并发性好，性能较高</td></tr><tr><td>重点在于页面下载</td><td>重点在于爬虫结构</td></tr><tr><td>定制灵活</td><td>一般定制灵活，深度定制困难</td></tr><tr><td>上手十分简单</td><td>入门稍难</td></tr></tbody></table><p>应用范围：非常小的需求用requests库，否则用Scrapy框架；定制程度高时可选用requests自搭框架。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;strong&gt;Scrapy爬虫框架&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;​        爬虫框架是实现爬虫功能的一个软件结构和功能组件集合；是一个半成品，能够帮助用户实现专业网络爬虫。&lt;/p&gt;
&lt;p&gt;​        Scarpy是一个功能非常强大的爬虫框架。它不仅能便捷地构建request，还有强大的 selector 能够方便地解析 response，可以将爬虫工程化、模块化。
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>Python学习/爬虫简介</title>
    <link href="https://wangchenhust.github.io/2020/02/18/Python%E5%AD%A6%E4%B9%A0/%E7%88%AC%E8%99%AB%E7%AE%80%E4%BB%8B/"/>
    <id>https://wangchenhust.github.io/2020/02/18/Python%E5%AD%A6%E4%B9%A0/%E7%88%AC%E8%99%AB%E7%AE%80%E4%BB%8B/</id>
    <published>2020-02-18T07:55:57.323Z</published>
    <updated>2020-02-18T08:38:09.051Z</updated>
    
    <content type="html"><![CDATA[<p><strong>爬虫定义</strong></p><p>爬虫是一个模拟人类请求网站行为的程序。可以自动请求网页、并将数据抓取下来，然后使用<strong>一定的规则</strong>提取有价值的数据。</p><p>从技术层面来说就是通过程序模拟浏览器请求站点的行为，把站点返回HTML代码/JSON数据/二进制数据（图片、视频） 爬到本地，进而提取自己需要的数据，存放起来使用。<a id="more"></a></p><p><strong>网页介绍</strong></p><p>网址(URL)：URL是统一资源定位符，是用于完整地描述Internet上网页和其他资源的地址的一种标识方法，也是爬虫的<strong>入口</strong>。互联网上的每个文件都有唯一的一个的URL，它包含的信息指出文件的位置以及浏览器应该怎么处理它。</p><p>网页加载方式</p><ul><li>同步加载：改变网址上的某些参数会导致网页发生改变。</li><li>异步加载：改变网址上的参数不会使网页发生改变。</li></ul><p>网页源码构成</p><ul><li>html：描述网页的内容结构。</li><li>css：描述网页的排版布局。</li><li>JavaScript：描述网页的时间处理，即鼠标或键盘在网页元素上动作后的程序。</li></ul><p>开发者工具</p><ul><li><p>定义：检查当前加载的HTML、CSS和JavaScript，显示每个资源页面的请求以及载入所花的时间。</p></li><li><p>打开方式：</p><p>（1）点击鼠标右键&gt;检查</p><p>（2）键盘按Fn+F12</p><p>（3）自定义以及控制Google Chrome&gt;更多工具&gt;开发者工具</p></li></ul><p><strong>Robots协议</strong></p><p>​    也称爬虫协议、机器人协议，用来告诉爬虫和搜索引擎哪些页面可以抓取、哪些不能抓取。它通常是一个叫作robots.txt的文本文件，一般放在网络的根目录下。</p><p>文件内容：</p><table><thead><tr><th>文件写法</th><th>说明</th></tr></thead><tbody><tr><td>User-agent:*</td><td>*代表的所有的搜索引擎种类，是一个通配符</td></tr><tr><td>Disallow:/abc/</td><td>这里定义是禁止爬寻abc目录下面的目录</td></tr><tr><td>Disallow:/abc/*.htm</td><td>禁止访问 /abc/目录下的所有以”.htm”为后缀的URL(包含子目录)</td></tr><tr><td>Allow: /tmp</td><td>允许爬寻tmp的整个目录</td></tr><tr><td>Allow: .htm$</td><td>仅允许访问以”.htm”为后缀的URL</td></tr></tbody></table><p>使用说明：</p><ol><li><p>自建网页时可以通过Robots工具来创建、校验、更新robots.txt文件，或查看网站robots.txt文件在百度生效的情况。</p></li><li><p>Robots工具暂不支持https站点。</p></li><li><p>Robots工具目前支持48k的文件内容检测，请保证创建的robots.txt文件不要过大，目录最长不超过250个字符。</p></li></ol><p>爬虫的主要流程：</p><ul><li><p>构造URL</p><p>爬虫要爬的数据，绝不仅仅是一个网页那么简单，有时候我们需要爬的是整个网站的数据，如果我们一个一个网页来获取url，那效率肯定太低了。所以在写爬虫程序之前，需要先知道url地址的规律，这样子才可以构造url列表，再从url列表中去url去爬我们需要的数据。</p></li></ul><p>发送请求，获取响应</p><p>通过HTTP库向目标站点发起请求，也就是发送一个Request等待服务器响应，如果服务器能正常响应，会得到一个Response，Response的内容便是所要获取的页面内容，类型可能是HTML，Json字符串，二进制数据（图片或者视频）等类型。</p><p>提取数据</p><p>返回的数据时html时，我们可以用正则表达式，或者是lxml模块配合xpath提取数据；返回的是json字符串时，我们可以用json模块进行数据解析；返回的是二进制数据时，可以做保存或者进一步的处理。</p><p>保存数据</p><p>保存形式多样，可以存为文本，也可以保存到数据库，或者保存特定格式的文件。</p><p>轻量级爬虫</p><p>“<strong>获取数据——解析数据——存储数据</strong>”是爬虫的三部曲，大部分爬虫都是按这样的流程来进行，这其实也是模拟了我们使用浏览器获取网页信息的过程。</p><p><strong>获取数据</strong></p><p>爬虫第一步操作就是模拟浏览器向服务器发送请求，python提供了功能齐全的类库来实现网络传输、服务器请求和响应。</p><p>Python自带的标准库<strong>urllib2</strong>使用的较多，它是python内置的HTTP请求库，如果只进行基本的爬虫网页抓取，那么urllib2足够用。</p><ul><li><p>urllib：用于操作URL的模块。Python自带的标准库<strong>urllib2</strong>使用的较多，是python内置的HTTP请求库，可以进行基本的爬虫网页抓取。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">file = urllib.request.urlopen(url_path).read().decode(）</span><br></pre></td></tr></table></figure></li><li><p>requests：基于 urllib 编写的，阻塞式 HTTP 请求库，发出一个请求，一直等待服务器响应后，程序才能进行下一步处理。</p></li><li><p>selenium：自动化测试工具。一个调用浏览器的 driver，通过这个库可以直接调用浏览器完成某些操作，比如输入验证码。</p></li><li><p>aiohttp：基于 asyncio 实现的 HTTP 框架。异步操作借助于 async/await 关键字，使用异步库进行数据抓取，可以大大提高效率。</p></li></ul><p><strong>解析数据</strong></p><p>爬虫需要的是页面指定的部分数据值，而不是整个页面的数据，这时往往需要先进行数据的解析再进行存储。从网页上采集到的数据的数据类型有很多种,主要有HTML、 javascript、JSON、XML等格式。解析库的使用等价于快捷地定位到具体的元素获取相应的信息。下面是常用的解析库。</p><p><strong>Beautiful Soup</strong></p><p>Beautiful Soup是借助网页的<u>结构和属性</u>等特性来解析网页的工具，对“标签树”解析、遍历和维护，能自动转换编码。支持Python标准库中的HTML解析器,还支持一些第三方的解析器。</p><img src="C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20200214161835436.png" alt="image-20200214161835436" style="zoom:25%;" /><p><strong>Re</strong></p><p>Re正则表达式通常被用来检索、替换那些符合某个模式(规则)的文本。re库主要用于字符串匹配。</p><p>1.raw string类型 (不包含转义符)r’text’</p><p>2.string类型</p><p><a href="https://www.jianshu.com/p/81873c1f9118" target="_blank" rel="noopener">主要功能函数</a></p><p>使用方法:</p><p>（1）函数式用法：一次次那个操作 </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rst = re.search(<span class="string">r'[1-9]\d&#123;5&#125;'</span>, <span class="string">'BIT 100081'</span>)</span><br></pre></td></tr></table></figure><p>（2）面向对象用法：编译后的多次操作 </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pat = re.compile(<span class="string">r'[1-9]\d&#123;5&#125;'</span>) </span><br><span class="line">rst = pat.search(<span class="string">'BIT 100081'</span>)</span><br></pre></td></tr></table></figure><p>Match对象</p><table><thead><tr><th align="center">属性</th><th align="center">说明</th></tr></thead><tbody><tr><td align="center">.string</td><td align="center">待匹配的文本</td></tr><tr><td align="center">.re</td><td align="center">匹配时使用的pattern对象</td></tr><tr><td align="center">.pos</td><td align="center">正则表达式搜索文本的开始位置</td></tr><tr><td align="center">.endpos</td><td align="center">正则表达式搜索文本的结束位置</td></tr></tbody></table><table><thead><tr><th align="center">方法</th><th align="center">说明</th></tr></thead><tbody><tr><td align="center">.group(0)</td><td align="center">获得<strong>第一次</strong>匹配后的字符串</td></tr><tr><td align="center">.start()</td><td align="center">匹配字符串在原始字符的开始位置</td></tr><tr><td align="center">.end()</td><td align="center">匹配字符串在原始字符的结束位置</td></tr><tr><td align="center">.sapn()</td><td align="center">返回（.start(),.end()）</td></tr></tbody></table><p>最小匹配操作符（在后面增加一个“？”）</p><table><thead><tr><th align="center">操作符</th><th align="center">说明</th></tr></thead><tbody><tr><td align="center">*?</td><td align="center">前一个字符0次或无限次扩展，最小匹配</td></tr><tr><td align="center">+?</td><td align="center">前一个字符1次或无限次扩展，最小匹配</td></tr><tr><td align="center">??</td><td align="center">前一个字符0次或1次扩展，最小匹配</td></tr><tr><td align="center">{m,n}?</td><td align="center">扩展前一个字符m次至n次（含n），最小匹配</td></tr></tbody></table><p><strong>Xpath</strong></p><p>Xpath最初是用来搜寻XML文档的，但是它同样适用于 HTML 文档的搜索。它提供了超过 100 个内建的函数。这些函数用于字符串值、数值、日期和时间比较、节点和 QName 处理、序列处理、逻辑值等等，并且XQuery和XPointer都构建于XPath基础上。</p><p><strong>css</strong></p><p>Css选择器是一种快速定位元素的方法。</p><p>数据存储</p><p>当需要爬取的数据量较小时，可以使用<strong>文档</strong>的形式来储存，支持txt、json、csv等格式。但当数据量变大，就需要<strong>数据库</strong>的储存方式了。</p><p><strong>小规模数据</strong></p><p>​    TXT文件</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> open(<span class="string">'example.txt'</span>,<span class="string">'w'</span>,encoding=<span class="string">'utf-8'</span>) <span class="keyword">as</span> file:</span><br><span class="line">file.write(data)</span><br></pre></td></tr></table></figure><p>​    JSON文件：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> open(<span class="string">'example.json'</span>,<span class="string">'w'</span>,encoding=<span class="string">'utf-8'</span>) <span class="keyword">as</span> file:</span><br><span class="line">file.write(json.dumps(data))</span><br></pre></td></tr></table></figure><p>​    CSV文件：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> open(<span class="string">'example.txt'</span>,<span class="string">'w'</span>,encoding=<span class="string">'utf-8'</span>) <span class="keyword">as</span> csvfile:</span><br><span class="line">writer = csv.write(csvfile)</span><br><span class="line">    writer.writerow(一行内容)</span><br></pre></td></tr></table></figure><p>大规模数据</p><ul><li>Mysql 作为关系型数据库的代表，拥有较为成熟的体系，成熟度很高，可以很好地去存储一些数据，但在在海量数据处理的时候效率会显著变慢，已然满足不了某些大数据的处理要求。</li><li>MongoDB已经流行了很长一段时间，相对于MySQL ，MongoDB可以方便你去存储一些非结构化的数据，比如各种评论的文本，图片的链接等等。你也可以利用PyMongo，更方便地在Python中操作MongoDB。因为这里要用到的数据库知识其实非常简单，主要是数据如何入库、如何进行提取，在需要的时候再学习就行。</li><li>Redis是一个不折不扣的内存数据库，Redis 支持的数据结构丰富，包括hash、set、list等。数据全部存在内存，访问速度快，可以存储大量的数据，一般应用于分布式爬虫的数据存储当中</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;strong&gt;爬虫定义&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;爬虫是一个模拟人类请求网站行为的程序。可以自动请求网页、并将数据抓取下来，然后使用&lt;strong&gt;一定的规则&lt;/strong&gt;提取有价值的数据。&lt;/p&gt;
&lt;p&gt;从技术层面来说就是通过程序模拟浏览器请求站点的行为，把站点返回HTML代码/JSON数据/二进制数据（图片、视频） 爬到本地，进而提取自己需要的数据，存放起来使用。
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>HTML和CSS学习笔记——慕课</title>
    <link href="https://wangchenhust.github.io/2020/02/01/%E5%89%8D%E7%AB%AF/HTML%E5%92%8CCSS%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E2%80%94%E2%80%94%E6%85%95%E8%AF%BE/"/>
    <id>https://wangchenhust.github.io/2020/02/01/%E5%89%8D%E7%AB%AF/HTML%E5%92%8CCSS%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E2%80%94%E2%80%94%E6%85%95%E8%AF%BE/</id>
    <published>2020-02-01T04:29:39.000Z</published>
    <updated>2020-04-21T15:57:33.352Z</updated>
    
    <content type="html"><![CDATA[<p>HTML和CSS学习笔记——慕课</p><p>网站与网页</p><p>网站：互联网上用于展示特定内容的相关网页集合。</p><p>网页：网站中的一页，一个网站中的网页通过“超链接”的方式被组织在一起。</p><p>主页的文件名通常是index</p><p>页面元素：LOGO站标、导航栏、文字链接、banner广告横幅、表单</p><a id="more"></a><p>从开发者角度：</p><p>网站：文件夹  网页：文件</p><p>浏览器：解析网页源代码、渲染网页。读取 HTML 文档，并以网页的形式显示出它们。</p><p>前端技术构成</p><p><img src="D:%5Csoftdownload%5COffice%5C%E6%9C%89%E9%81%93%E4%BA%91%5CFile%5Cwangchen_hust@163.com%5Cc861e5b2047748ffb76222e4b8708826%5Cclipboard.png" alt="img"></p><p><strong>HTML：HyperText MarkUp Language</strong></p><p>标签、元素：</p><p><strong>标签</strong>由&lt;&gt;包围，成对出现。结束标签比开始标签多一个/，例如<title>百度一下</title>,这个整体称为<strong>元素。</strong></p><ul><li>单独出现标签<img    /></li><li>标签嵌套：<html><body></body></html>，注意缩进</li></ul><p>编辑器：</p><p>记事本</p><p>Sublime Text3</p><p>emmet插件</p><p>webstorm</p><ul><li>Adobe Dreamweaver</li><li>Microsoft Expression Web</li><li>CoffeeCup HTML Editor</li></ul><p>基本的HTML标签</p><p>标题： <h1> - <h6> </p><p>段落：<p>  注：段落内部连续空格显示为一个空格</p><p>段内换行：<br /></p><p>段内分组：<span>,将需要特殊表达的文字放在<span>标签对中</p><p>预留格式：<pre >，一对放在文本前后，文本中的空格和换行符都会被保留，就不需要加<br />、&nbsp等，适用于代码</p><p>水平线：<hr /></p><p>链接：<a> href 属性指定链接的地址，style属性：无下划线链接style="text-decoration:none"，Target 属性定义文档在何处显示，如target="_blank"表示在新窗口打开文档；name 属性创建书签，对读者是不可见，将 # 符号和锚名称添加到 URL 的末端，就可以直接链接到 tips 这个命名锚了，通常用于目录。</p><p>图像： <img> </p><p>定义图像地图：<map></p><p>定义图像地图中的可点击区域:<area></p><p>空格字符：&nbsp;特殊字符要求全小写</p><p>注释：<!-- 这是一段注释，可跨行   --></p><p>短引用（“”）：可以用一对<q>标签，或者直接用“</p><p>长引用:<blockquote>，会缩进</p><p>缩略词：<abbr>，鼠标放在WHO会有显示。例如：<p><abbr title="World Health Organization">WHO</abbr> 成立于 1948 年。</p></p><p>定义：<dfn>，<p><dfn title="World Health Organization">WHO</dfn> 成立于 1948 年。</p></p><p>定义文档或文章的联系信息：<address>，以斜体显示内容</p><p>著作的标题： <cite> ，以斜体显示内容</p><p>覆盖当前文本方向：<bdo>，文字反序。例：<bdo dir="rtl">This text will be written from right to left</bdo></p><p>键盘输入:<kbd> </p><p>计算机输出示例: <samp></p><p>编程代码示例: <code> </p><p>数学变量: <var> ,例：<p><var>E</var> = <var>m</var> <var>c</var><sup>2</sup></p></p><p>区域：<div>,块级元素,能够用作其他 HTML 元素的容器，只需要在body中的name属性值改为定义的类名。</p><p>无序列表：<ul>，此列项目使用粗体圆点标记</p><p>有序列表：<ol>，此列项目使用数字序号标记</p><p>列表项：<li></p><p>自定义列表以 <dl> 标签开始、列表项<dt>、描述<dd></p><p>表格：<table>     分行<tr>  单元格<td> 表头单元格<th>加粗的</p><p>表单：<form></p><p>表单元素：，用于收集用户信息。在typr属性值设置输入、确定、重置、单选框radio(注意name中的值要为一样的）、复选框checkbox、下拉列表框<select> <option>、文本域Textarea</p><p>语义化：强调：<em> 对应着无语义的<i>; 重点强调：<strong>对应着无语义的<b>,自定义 <dl> 、<dt>、<dd></p><p>HTML样式属性</p><p>背景颜色：background-color </p><h2 style="background-color:red">This is a heading</h2><p>字体、颜色、尺寸：font-family、color 以及 font-size </p><p style="font-family:arial;color:red;font-size:20px;">A paragraph.</p><p>文本对齐：text-align</p><h1 style="text-align:center">This is a heading</h1><p>内部样式表：<head>内容中添加需要的样式</p><p>外部样式表：<head>内容中添加外部herf</p><p>内联样式：应用到个别元素，是在相关的标签中使用样式属性。针对某一句话。</p><p><strong>CSS</strong></p><p>颜色：</p><ul><li>十六进制色  #RRGGBB</li><li>RGB 颜色    rgb(0,0,255)</li><li>RGBA 颜色  rgba(red, green, blue, alpha)</li><li>HSL 颜色    hsl(120,65%,75%)</li><li>HSLA 颜色  hsla(hue, saturation, lightness, alpha)</li></ul><p>行内样式：在<p>里面定义属性style</p><p>内嵌样式：在<head>中添加css的<style>标签</p><p>单独文件样式表：用一个单独文件style.css定义样式，然后再用<link>连接到css文件，可以重复使用便于修改。优先级：多重样式可以重叠、覆盖；采用就近原则；行内>内嵌>链接>默认样式。</p><ul><li>css选择器</li></ul><p>标签</p><style>​               body{background-color: #ccc;​            text-align: :center;}​        h1{font-size: 20px;}​        p{font-size: :24px;​            color: red;}​    </style><p>类别（与ID的区别是可多次被引用，作用于多个网页元素上）</p><p><strong>.</strong>one{font-size: 12px;</p><p>​            color:white;}</p><p class="one">类别</p><p>ID选择器</p><p>#two{font-size: :48px;</p><p>​            color: blue;}</p><p id="two">ID选择器</p><p>集体</p><p>h1,p{color:yellow;}</p><p>嵌套</p><p>p span{color:green;}</p><p><span>嵌</span>套</p><p>全局声明</p><p>*****{text-align: center;}</p><ul><li>混用</li></ul><p>多个claa选择器可以混用，用空格隔开；</p><div class="one two left">……</div><p>id和class混用；</p><div id="my" class="one two left">……</div><p>id选择器不可以多个同时使用。从语义上来说，id选择器被唯一使用，不要被多次使用，也不要同时使用</p><ul><li>css样式</li></ul><p>单位</p><ol><li>px 像素</li><li>em 自适应字体  1em 2em</li><li>% 百分比</li></ol><p>颜色</p><ol><li>颜色名red,green,blue</li><li>rgb(x,x,x)</li><li>rgb(x%,x%,x%)</li><li>rgba(x,x,x,x);a表示透明度，取值在[0-1]</li><li>#rrggbb十六进制</li></ol><p>文本</p><p>文本颜色color</p><p>字符间距letter-spacing :2px  -3px</p><p>行高line-height  :1.5em  14px   120%  常用于文本垂直居中对齐，将文本与图片垂直居中对齐，采用line-height与height相等</p><p>对齐text-align  :right left center justify</p><p>装饰线text-decoration  :none（常用于超链接） overline（淘宝价格折扣删除线） underline line-through  </p><p>首行缩进text-index 2em</p><p>字体</p><p>font-family</p><p>font-size  14px 120%</p><p>font-style 斜体italic</p><p>font-weight 粗体bold</p><p>font在一个声明中设置所有字体属性。次序为：斜体 粗体 字号/行高 字体</p><p>背景(空元素需要先定义元素的高度和宽度）</p><p>background-color</p><p>background-image:url()</p><p>background-repeat:repeat repeat-x repeat-y no-repeatb背景单元格图片填充，xy表示方向</p><p>上面都可写在一个里面  background:颜色 图片 repeat</p><p>超链接（：伪类选择器）</p><p>a:link 普通的，未被访问</p><p>a:visited用户已访问的样式</p><p>a:hover 鼠标位于链接上方停留时的样式，必须位于a:link  a:visited后面</p><p>a:active 链接被点击的时刻的样式 必须位于a:hover后面</p><p>  次序记忆法：love&hate</p><p>列表List</p><p>list-style-image为列表标志设置图像</p><p>list-style-position标志的位置</p><p>list-style-type标志的类型</p><p>list-style所有属性设置于一个列表中</p><p>表格</p><p>大小：width height</p><p>边框：border  </p><p>​      border-collaspe将内层边框与外层边框重合</p><p>奇偶选择器：:nth-child(odd|even)多用于奇偶分行的表格</p><p>​      例子：tr:nth-child(odd){background-color:red;}</p><p>CSS布局与定位</p><p>盒子模型：页面元素大小、边框、与其他元素距离</p><p><img src="D:%5Csoftdownload%5COffice%5C%E6%9C%89%E9%81%93%E4%BA%91%5CFile%5Cwangchen_hust@163.com%5C27069718933c4acea12ceeaa396e5518%5Cclipboard.png" alt="img"></p><ul><li>组成：</li></ul><p>content内容</p><p>css样式</p><p>盒子实际宽度：content + margin+ border+padding</p><p>margin设置：</p><p>1.margin 1px;</p><p>2.margin:1px 2px ;</p><p>3.margin:1px 2px 3px 4px;分别对应top right bottom left</p><p>水平居中</p><p>图片和文字居中 text-align:center;</p><p>div水平居中 margin:0 suto;使得div区域在盒子里水平居中</p><ul><li>对浏览器默认设置清零</li></ul><p>*{margin :0;</p><p>  padding: 0;}</p><p>定位机制：文档流、浮动定位、层定位</p><ul><li>文档流</li></ul><p><img src="D:%5Csoftdownload%5COffice%5C%E6%9C%89%E9%81%93%E4%BA%91%5CFile%5Cwangchen_hust@163.com%5Cc0b7c12dc8294b6eb9bbf7ba2ee73ceb%5Cclipboard.png" alt="img"></p><p>将元素显示为block元素</p><p>a{    display:block;使得元素a具有块状元素特点； }</p><p>将元素显示为inline元素</p><p>div{    display:inline; }</p><p>将元素显示为inline-block元素</p><p>img{    display:inlineblock; }</p><ul><li>浮动定位</li></ul><p>div用于横向排列</p><p>float用处：1)希望图片位于文字左侧或右侧就把float属性设为left right;  2)用于列的布局。</p><p>使用clear属性时注意侧栏向右浮动，并且短于主内容区域。页脚（footer）按浮动所要求的向上跳到了可能的空间，这时候需要用<strong>#footer{clear:both}</strong>来清除两侧的浮动，保证footer位于下端中间。</p><ul><li>层定位</li></ul><p>position（left、right、top、bottom、z-index前后叠加次序）</p><ul><li><ul><li>static默认值：没有定位，元素出现在正常流中，上述5种无效。</li><li>fixed固定定位：相对于<strong>浏览器窗口</strong>进行定位</li><li>relative相对定位：总是相对于<strong>直接父元素</strong>进行定位，无论父元素是什么定位方式</li><li>absolute绝对定位：相对于<strong>static定位以外的第一个父元素</strong>进行定位，如果其父层中都未定义absolute或relative，则将相对<strong>body</strong>定位。</li></ul></li></ul><p>一般将relative+absolute结合使用，习惯将外层定为relative,内层定位absolute</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;HTML和CSS学习笔记——慕课&lt;/p&gt;
&lt;p&gt;网站与网页&lt;/p&gt;
&lt;p&gt;网站：互联网上用于展示特定内容的相关网页集合。&lt;/p&gt;
&lt;p&gt;网页：网站中的一页，一个网站中的网页通过“超链接”的方式被组织在一起。&lt;/p&gt;
&lt;p&gt;主页的文件名通常是index&lt;/p&gt;
&lt;p&gt;页面元素：LOGO站标、导航栏、文字链接、banner广告横幅、表单&lt;/p&gt;
    
    </summary>
    
    
      <category term="前端" scheme="https://wangchenhust.github.io/categories/%E5%89%8D%E7%AB%AF/"/>
    
    
      <category term="basic web" scheme="https://wangchenhust.github.io/tags/basic-web/"/>
    
  </entry>
  
  <entry>
    <title>Hello World</title>
    <link href="https://wangchenhust.github.io/2020/01/01/hello-world/"/>
    <id>https://wangchenhust.github.io/2020/01/01/hello-world/</id>
    <published>2020-01-01T12:57:05.239Z</published>
    <updated>2020-02-18T08:39:17.635Z</updated>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html" target="_blank" rel="noopener">Deployment</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Welcome to &lt;a href=&quot;https://hexo.io/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Hexo&lt;/a&gt;! This is your very first post. Check &lt;a href=&quot;https://hexo.
      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>初始化与类的加载</title>
    <link href="https://wangchenhust.github.io/2019/07/01/%E5%88%9D%E5%A7%8B%E5%8C%96%E5%8F%8A%E7%B1%BB%E7%9A%84%E5%8A%A0%E8%BD%BD/"/>
    <id>https://wangchenhust.github.io/2019/07/01/%E5%88%9D%E5%A7%8B%E5%8C%96%E5%8F%8A%E7%B1%BB%E7%9A%84%E5%8A%A0%E8%BD%BD/</id>
    <published>2019-07-01T04:29:39.000Z</published>
    <updated>2020-01-01T14:48:41.681Z</updated>
    
    <content type="html"><![CDATA[<p>​    尽管之前已经讲了很多关于初始化的知识，此处做一个小小的总结。</p><ul><li>类只有在用到时才进行加载，并且只加载一次，首先加载main的入口类，因为它第一个被用到喽，如果入口类有父类，则先加载入口类的父类。第一次加载时会按照定义顺序初始化类中的静态区，即被static修饰的，注意static方法里的局部变量是不会被初始化的，如果有人问如果static方法里面万一有个static变量怎么办？？好问题，不过这种情况是不存在的，因为static不能修饰局部变量。<a id="more"></a></li><li>只有在创建对象时才会对非静态区进行初始化，最后调用构造方法，即在调用构造方法前，所有的初始化都已经完成，换个角度而言，在对象创建之前，非静态区都无法被使用，所以就没必要初始化。</li><li>有一点难以理解的是【欢迎讨论】，导出类的构造方法一定会调用基类的构造方法，尽管调用基类的代码在导出类构造方法中，即看似在导出类非静态对象或变量之后，但初始化顺序仍然为先基类构造方法再导出类非静态对象或变量，再是导出类构造方法。</li></ul><p>所以一般来说初始化及加载的流程为：</p><p>加载类&gt;&gt;<strong>基类的</strong>static区（static段、static对象和static变量）&gt;<strong>导出类的</strong>static区（static段、static对象和static变量）&gt;&gt;【创建对象】&gt;&gt;<strong>基类的</strong>非静态对象或变量&gt;<strong>基类的</strong>构造方法&gt;&gt;<strong>导出类的</strong>非静态对象或变量&gt;<strong>导出类的</strong>构造方法。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Base</span></span>&#123;</span><br><span class="line">    <span class="keyword">static</span> <span class="keyword">int</span> i;</span><br><span class="line">    <span class="keyword">static</span>&#123;</span><br><span class="line">        System.out.println(<span class="string">"Base static"</span>);</span><br><span class="line">        System.out.println(<span class="string">"Static int i = "</span> + i);</span><br><span class="line">    &#125;</span><br><span class="line">    &#123;</span><br><span class="line">        System.out.println(<span class="string">"Base notStatic block"</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">Base</span><span class="params">(<span class="keyword">int</span> i)</span></span>&#123;</span><br><span class="line">        System.out.println(<span class="string">"Base constructor"</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Test</span> <span class="keyword">extends</span> <span class="title">Base</span></span>&#123;</span><br><span class="line">    <span class="keyword">static</span>&#123;</span><br><span class="line">        System.out.println(<span class="string">"Test static"</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">Test</span><span class="params">()</span></span>&#123;</span><br><span class="line">        <span class="keyword">super</span>(<span class="number">1</span>);</span><br><span class="line">        System.out.println(<span class="string">"Test constructor"</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    &#123;</span><br><span class="line">        System.out.println(<span class="string">"Test notStatic block"</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        Test test = <span class="keyword">new</span> Test();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/*Output:</span></span><br><span class="line"><span class="comment">    Base static</span></span><br><span class="line"><span class="comment">    Static int i = 0</span></span><br><span class="line"><span class="comment">    Test static</span></span><br><span class="line"><span class="comment">    Base notStatic block</span></span><br><span class="line"><span class="comment">    Base constructor</span></span><br><span class="line"><span class="comment">    Test notStatic block</span></span><br><span class="line"><span class="comment">    Test constructor</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;​    尽管之前已经讲了很多关于初始化的知识，此处做一个小小的总结。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;类只有在用到时才进行加载，并且只加载一次，首先加载main的入口类，因为它第一个被用到喽，如果入口类有父类，则先加载入口类的父类。第一次加载时会按照定义顺序初始化类中的静态区，即被static修饰的，注意static方法里的局部变量是不会被初始化的，如果有人问如果static方法里面万一有个static变量怎么办？？好问题，不过这种情况是不存在的，因为static不能修饰局部变量。
    
    </summary>
    
    
      <category term="Java" scheme="https://wangchenhust.github.io/categories/Java/"/>
    
    
      <category term="Thinking_in_Java" scheme="https://wangchenhust.github.io/tags/Thinking-in-Java/"/>
    
  </entry>
  
</feed>
