<!DOCTYPE html><html lang="zh-Hans"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="description" content="深度学习/LeNet"><meta name="keywords" content=""><meta name="author" content="WangChen"><meta name="copyright" content="WangChen"><title>深度学习/LeNet | MorningCoder</title><link rel="shortcut icon" href="/wangchenhust.github.io/melody-favicon.ico"><link rel="stylesheet" href="/wangchenhust.github.io/css/index.css?version=1.7.0"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css?version=1.7.0"><meta name="format-detection" content="telephone=no"><meta http-equiv="x-dns-prefetch-control" content="on"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><script>var GLOBAL_CONFIG = { 
  root: '/wangchenhust.github.io/',
  algolia: undefined,
  localSearch: undefined,
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  }
} </script><meta name="generator" content="Hexo 4.2.0"><link rel="alternate" href="/wangchenhust.github.io/atom.xml" title="MorningCoder" type="application/atom+xml">
</head><body><i class="fa fa-arrow-right" id="toggle-sidebar" aria-hidden="true"></i><div id="sidebar" data-display="true"><div class="toggle-sidebar-info text-center"><span data-toggle="切换文章详情">切换站点概览</span><hr></div><div class="sidebar-toc"><div class="sidebar-toc__title">目录</div><div class="sidebar-toc__progress"><span class="progress-notice">你已经读了</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar"></div></div><div class="sidebar-toc__content"></div></div><div class="author-info hide"><div class="author-info__avatar text-center"><img src="/wangchenhust.github.io/img/avatar.png"></div><div class="author-info__name text-center">WangChen</div><div class="author-info__description text-center">Stay hungry, stay foolish 主要涉及到编程（JS，Python，Linux等）和前端学习（HTML/CSS），用于个人整理知识点，回顾复习与反思</div><hr><div class="author-info-articles"><a class="author-info-articles__archives article-meta" href="/wangchenhust.github.io/archives"><span class="pull-left">文章</span><span class="pull-right">13</span></a><a class="author-info-articles__tags article-meta" href="/wangchenhust.github.io/tags"><span class="pull-left">标签</span><span class="pull-right">2</span></a><a class="author-info-articles__categories article-meta" href="/wangchenhust.github.io/categories"><span class="pull-left">分类</span><span class="pull-right">2</span></a></div></div></div><div id="content-outer"><div class="no-bg" id="top-container"><div id="page-header"><span class="pull-left"> <a id="site-name" href="/wangchenhust.github.io/">MorningCoder</a></span><i class="fa fa-bars toggle-menu pull-right" aria-hidden="true"></i><span class="pull-right menus">   <a class="site-page" href="/">Home</a><a class="site-page" href="/archives">Archives</a><a class="site-page" href="/tags">Tags</a><a class="site-page" href="/categories">Categories</a></span><span class="pull-right"></span></div><div id="post-info"><div id="post-title">深度学习/LeNet</div><div id="post-meta"><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2020-04-06</time></div></div></div><div class="layout" id="content-inner"><article id="post"><div class="article-container" id="post-content"><p>手写字体识别模型LeNet5诞生于1994年，是最早的卷积神经网络之一。LeNet5通过巧妙的设计，利用卷积、参数共享、池化等操作提取特征，避免了大量的计算成本，最后再使用全连接神经网络进行分类识别，这个网络也是最近大量神经网络架构的起点。</p>
<p><img src="D:%5Csoftdownload%5COffice%5C%E6%9C%89%E9%81%93%E4%BA%91%5CFile%5Cwangchen_hust@163.com%5C3c13e6bdf8fc48e29f0c588a2e1a7fff%5Cclipboard.png" alt="img"></p>
<p>LeNet5由7层CNN（不包含输入层）组成，上图中输入的原始图像大小是32×32像素，卷积层用Ci表示，子采样层（pooling，池化）用Si表示，全连接层用Fi表示。下面逐层介绍其作用和示意图上方的数字含义。</p>
<p>1、C1层（卷积层）：6@28×28</p>
<p>该层使用了6个卷积核，每个卷积核的大小为5×5，这样就得到了6个feature map（特征图）。</p>
<p>（1）特征图大小</p>
<p>每个卷积核（5×5）与原始的输入图像（32×32）进行卷积，这样得到的feature map（特征图）大小为（32-5+1）×（32-5+1）= 28×28</p>
<p>卷积核与输入图像按卷积核大小逐个区域进行匹配计算，匹配后原始输入图像的尺寸将变小，因为边缘部分卷积核无法越出界，只能匹配一次，匹配计算后的尺寸变为Cr×Cc=（Ir-Kr+1）×（Ic-Kc+1），其中Cr、Cc，Ir、Ic，Kr、Kc分别表示卷积后结果图像、输入图像、卷积核的行列大小。</p>
<p>（2）参数个数</p>
<p>由于参数（权值）共享的原因，对于同个卷积核每个神经元均使用相同的参数，因此，参数个数为（5×5+1）×6= 156，其中5×5为卷积核参数，1为偏置参数</p>
<p>（3）连接数</p>
<p>卷积后的图像大小为28×28，因此每个特征图有28×28个神经元，每个卷积核参数为（5×5+1）×6，因此，该层的连接数为（5×5+1）×6×28×28=122304</p>
<p>2、S2层（下采样层，也称池化层）：6@14×14</p>
<p>（1）特征图大小</p>
<p>这一层主要是做池化或者特征映射（特征降维），池化单元为2×2，因此，6个特征图的大小经池化后即变为14×14。回顾本文刚开始讲到的池化操作，池化单元之间没有重叠，在池化区域内进行聚合统计后得到新的特征值，因此经2×2池化后，每两行两列重新算出一个特征值出来，相当于图像大小减半，因此卷积后的28×28图像经2×2池化后就变为14×14。</p>
<p>这一层的计算过程是：2×2 单元里的值相加，然后再乘以训练参数w，再加上一个偏置参数b（每一个特征图共享相同的w和b)，然后取sigmoid值（S函数：0-1区间），作为对应的该单元的值。卷积操作与池化的示意图如下：</p>
<p>这里写图片描述</p>
<p>（2）参数个数</p>
<p>S2层由于每个特征图都共享相同的w和b这两个参数，因此需要2×6=12个参数</p>
<p>（3）连接数</p>
<p>下采样之后的图像大小为14×14，因此S2层的每个特征图有14×14个神经元，每个池化单元连接数为2×2+1（1为偏置量），因此，该层的连接数为（2×2+1）×14×14×6 = 5880</p>
<p>3、C3层（卷积层）：16@10×10</p>
<p>C3层有16个卷积核，卷积模板大小为5×5。</p>
<p>（1）特征图大小</p>
<p>与C1层的分析类似，C3层的特征图大小为（14-5+1）×（14-5+1）= 10×10</p>
<p>（2）参数个数</p>
<p>需要注意的是，C3与S2并不是全连接而是部分连接，有些是C3连接到S2三层、有些四层、甚至达到6层，通过这种方式提取更多特征，连接的规则如下表所示：</p>
<p>这里写图片描述</p>
<p>例如第一列表示C3层的第0个特征图（feature map）只跟S2层的第0、1和2这三个feature maps相连接，计算过程为：用3个卷积模板分别与S2层的3个feature maps进行卷积，然后将卷积的结果相加求和，再加上一个偏置，再取sigmoid得出卷积后对应的feature map了。其它列也是类似（有些是3个卷积模板，有些是4个，有些是6个）。因此，C3层的参数数目为（5×5×3+1）×6 +（5×5×4+1）×9 +5×5×6+1 = 1516</p>
<p>（3）连接数</p>
<p>卷积后的特征图大小为10×10，参数数量为1516，因此连接数为1516×10×10= 151600</p>
<p>4、S4（下采样层，也称池化层）：16@5×5</p>
<p>（1）特征图大小</p>
<p>与S2的分析类似，池化单元大小为2×2，因此，该层与C3一样共有16个特征图，每个特征图的大小为5×5。</p>
<p>（2）参数数量</p>
<p>与S2的计算类似，所需要参数个数为16×2 = 32</p>
<p>（3）连接数</p>
<p>连接数为（2×2+1）×5×5×16 = 2000</p>
<p>5、C5层（卷积层）：120</p>
<p>（1）特征图大小</p>
<p>该层有120个卷积核，每个卷积核的大小仍为5×5，因此有120个特征图。由于S4层的大小为5×5，而该层的卷积核大小也是5×5，因此特征图大小为（5-5+1）×（5-5+1）= 1×1。这样该层就刚好变成了全连接，这只是巧合，如果原始输入的图像比较大，则该层就不是全连接了。</p>
<p>（2）参数个数</p>
<p>与前面的分析类似，本层的参数数目为120×（5×5×16+1） = 48120</p>
<p>（3）连接数</p>
<p>由于该层的特征图大小刚好为1×1，因此连接数为48120×1×1=48120</p>
<p>6、F6层（全连接层）：84</p>
<p>（1）特征图大小</p>
<p>F6层有84个单元，之所以选这个数字的原因是来自于输出层的设计，对应于一个7×12的比特图，如下图所示，-1表示白色，1表示黑色，这样每个符号的比特图的黑白色就对应于一个编码。</p>
<p>这里写图片描述</p>
<p>该层有84个特征图，特征图大小与C5一样都是1×1，与C5层全连接。</p>
<p>（2）参数个数</p>
<p>由于是全连接，参数数量为（120+1）×84=10164。跟经典神经网络一样，F6层计算输入向量和权重向量之间的点积，再加上一个偏置，然后将其传递给sigmoid函数得出结果。</p>
<p>（3）连接数</p>
<p>由于是全连接，连接数与参数数量一样，也是10164。</p>
<p>7、OUTPUT层（输出层）：10</p>
<p>Output层也是全连接层，共有10个节点，分别代表数字0到9。如果第i个节点的值为0，则表示网络识别的结果是数字i。</p>
<p>（1）特征图大小</p>
<p>该层采用径向基函数（RBF）的网络连接方式，假设x是上一层的输入，y是RBF的输出，则RBF输出的计算方式是：</p>
<p>这里写图片描述</p>
<p>上式中的Wij的值由i的比特图编码确定，i从0到9，j取值从0到7×12-1。RBF输出的值越接近于0，表示当前网络输入的识别结果与字符i越接近。</p>
<p>（2）参数个数</p>
<p>由于是全连接，参数个数为84×10=840</p>
<p>（3）连接数</p>
<p>由于是全连接，连接数与参数个数一样，也是840</p>
</div></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">WangChen</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="https://wangchenhust.github.io/2020/04/06/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/LeNet/">https://wangchenhust.github.io/2020/04/06/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/LeNet/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank" rel="noopener">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://wangchenhust.github.io">MorningCoder</a>！</span></div></div><div class="post-meta__tag-list"></div><nav id="pagination"><div class="prev-post pull-left"><a href="/wangchenhust.github.io/2020/04/06/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/AlexNet/"><i class="fa fa-chevron-left">  </i><span>深度学习/AlexNet</span></a></div><div class="next-post pull-right"><a href="/wangchenhust.github.io/2020/04/06/Mysql%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"><span>Mysql学习笔记</span><i class="fa fa-chevron-right"></i></a></div></nav></div></div><footer><div class="layout" id="footer"><div class="copyright">&copy;2013 - 2020 By WangChen</div><div class="framework-info"><span>驱动 - </span><a href="http://hexo.io" target="_blank" rel="noopener"><span>Hexo</span></a><span class="footer-separator">|</span><span>主题 - </span><a href="https://github.com/Molunerfinn/hexo-theme-melody" target="_blank" rel="noopener"><span>Melody</span></a></div><div class="busuanzi"><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><span id="busuanzi_container_page_pv"><i class="fa fa-file"></i><span id="busuanzi_value_page_pv"></span><span></span></span></div></div></footer><i class="fa fa-arrow-up" id="go-up" aria-hidden="true"></i><script src="https://cdn.jsdelivr.net/npm/animejs@latest/anime.min.js"></script><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-animate@latest/velocity.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-ui-pack@latest/velocity.ui.min.js"></script><script src="/wangchenhust.github.io/js/utils.js?version=1.7.0"></script><script src="/wangchenhust.github.io/js/fancybox.js?version=1.7.0"></script><script src="/wangchenhust.github.io/js/sidebar.js?version=1.7.0"></script><script src="/wangchenhust.github.io/js/copy.js?version=1.7.0"></script><script src="/wangchenhust.github.io/js/fireworks.js?version=1.7.0"></script><script src="/wangchenhust.github.io/js/transition.js?version=1.7.0"></script><script src="/wangchenhust.github.io/js/scroll.js?version=1.7.0"></script><script src="/wangchenhust.github.io/js/head.js?version=1.7.0"></script><script>if(/Android|webOS|iPhone|iPod|iPad|BlackBerry/i.test(navigator.userAgent)) {
  $('#nav').addClass('is-mobile')
  $('footer').addClass('is-mobile')
  $('#top-container').addClass('is-mobile')
}</script></body></html>