<!DOCTYPE html><html lang="zh-Hans"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="description" content="深度学习/Network in Network"><meta name="keywords" content=""><meta name="author" content="WangChen"><meta name="copyright" content="WangChen"><title>深度学习/Network in Network | MorningCoder</title><link rel="shortcut icon" href="/wangchenhust.github.io/melody-favicon.ico"><link rel="stylesheet" href="/wangchenhust.github.io/css/index.css?version=1.7.0"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css?version=1.7.0"><meta name="format-detection" content="telephone=no"><meta http-equiv="x-dns-prefetch-control" content="on"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><script>var GLOBAL_CONFIG = { 
  root: '/wangchenhust.github.io/',
  algolia: undefined,
  localSearch: undefined,
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  }
} </script><meta name="generator" content="Hexo 4.2.0"><link rel="alternate" href="/wangchenhust.github.io/atom.xml" title="MorningCoder" type="application/atom+xml">
</head><body><i class="fa fa-arrow-right" id="toggle-sidebar" aria-hidden="true"></i><div id="sidebar" data-display="true"><div class="toggle-sidebar-info text-center"><span data-toggle="切换文章详情">切换站点概览</span><hr></div><div class="sidebar-toc"><div class="sidebar-toc__title">目录</div><div class="sidebar-toc__progress"><span class="progress-notice">你已经读了</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar"></div></div><div class="sidebar-toc__content"></div></div><div class="author-info hide"><div class="author-info__avatar text-center"><img src="/wangchenhust.github.io/img/avatar.png"></div><div class="author-info__name text-center">WangChen</div><div class="author-info__description text-center">Stay hungry, stay foolish 主要涉及到编程（JS，Python，Linux等）和前端学习（HTML/CSS），用于个人整理知识点，回顾复习与反思</div><hr><div class="author-info-articles"><a class="author-info-articles__archives article-meta" href="/wangchenhust.github.io/archives"><span class="pull-left">文章</span><span class="pull-right">13</span></a><a class="author-info-articles__tags article-meta" href="/wangchenhust.github.io/tags"><span class="pull-left">标签</span><span class="pull-right">2</span></a><a class="author-info-articles__categories article-meta" href="/wangchenhust.github.io/categories"><span class="pull-left">分类</span><span class="pull-right">2</span></a></div></div></div><div id="content-outer"><div class="no-bg" id="top-container"><div id="page-header"><span class="pull-left"> <a id="site-name" href="/wangchenhust.github.io/">MorningCoder</a></span><i class="fa fa-bars toggle-menu pull-right" aria-hidden="true"></i><span class="pull-right menus">   <a class="site-page" href="/">Home</a><a class="site-page" href="/archives">Archives</a><a class="site-page" href="/tags">Tags</a><a class="site-page" href="/categories">Categories</a></span><span class="pull-right"></span></div><div id="post-info"><div id="post-title">深度学习/Network in Network</div><div id="post-meta"><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2020-04-06</time></div></div></div><div class="layout" id="content-inner"><article id="post"><div class="article-container" id="post-content"><p>这是14年ICLR的一篇paper，虽不是在imagenet上的冠军模型，但其采用了少量的参数就松松击败了Alexnet网络，Alexnet网络参数大小是230M，采用这篇paper的算法仅仅29M。</p>
<p>该论文主要的contribution是提出mlpconv，相比于传统的卷积神经网络来说不易过拟合，而且可以进行全局平均池化。下面具体讲述一些创新点：</p>
<p><strong>卷积层的改进–mlpconv</strong></p>
<p>之前同样的卷积层可以认为是线性的, 因为只是局部接收域与卷积核进行加权求和，然后可能接一个relu激活函数，但它的抽象提取特征的能力还是不够的。所以，在这篇文章中，引入了mlpconv。提出了 mlpcon 结构，它用多层的感知器（多层的全连接层）来替代单纯的卷积神经网络中的加权求和，也就是原来的feature map经过MLP的映射再输出。其中 mlpcon 指的是： multilayer perceptron + convolution，mlp被共享于所有的局部感受野。如下图所示：</p>
<p><img src="D:%5Csoftdownload%5COffice%5C%E6%9C%89%E9%81%93%E4%BA%91%5CFile%5Cwangchen_hust@163.com%5C0895d8da88424fe79ce4dc578b626de7%5Cclipboard.png" alt="img"></p>
<p>其实和原来的差别就体现在中间接了MLP层，这样可以提高其非线性。如上图右，提高每一层卷积层对于复杂特征的识别能力，这里举个可能不那么恰当的例子，传统的CNN网络，每一层的卷积层相当于一个只会做单一任务，你必须要增加海量的卷积核来达到完成特定量类型的任务，而MLPconv的每层conv有更加大的能力，每一层能够做多种不同类型的任务，在选择卷积核时只需要很少量的部分</p>
<p><strong>整体结构</strong></p>
<p>可以看到就是多个MLPconv结构组合，再之后接上global average pooling组成：</p>
<p><img src="D:%5Csoftdownload%5COffice%5C%E6%9C%89%E9%81%93%E4%BA%91%5CFile%5Cwangchen_hust@163.com%5C4e2d08c5a72048359e9d7ae039937921%5Cclipboard.png" alt="img"></p>
<p><strong>1×1卷积的作用</strong></p>
<p>1×1的卷积层引起人们的重视应该就是在NIN的结构中，论文中利用MLP代替传统的线性卷积核，从而提高网络的表达能力。文中同时利用了跨通道pooling的角度解释，认为文中提出的MLP其实等价于在传统卷积核后面接cccp层，从而实现多个feature map的线性组合，实现跨通道的信息整合。而cccp层是等价于1×1卷积的，因此细看NIN的caffe实现，就是在每个传统卷积层后面接了两个cccp层（其实就是接了两个1×1的卷积层）。这就实现跨通道的交互和信息整合。</p>
<p><strong>使用全局均值池化</strong></p>
<p>论文中还采用全局均值池化来解决传统CNN网络中最后全连接层参数过于复杂的特点，而且全连接会造成网络的泛化能力差，（Alexnet中使用dropout来提高网络的泛化能力)，至于global average pooling 与average pooling的区别如下<strong>:</strong></p>
<p>如最后一个卷积层输出10个feature map，average pooling 是对每个feature map分别求平均，输出10个feature map。 global average pooling是对每个feature map内部取平均，每个feature map变成一个值（因为kernel的大小设置成和feature map的相同），10个feature map就变成一个10维的向量，然后直接输入到softmax中。如下图</p>
<p><img src="D:%5Csoftdownload%5COffice%5C%E6%9C%89%E9%81%93%E4%BA%91%5CFile%5Cwangchen_hust@163.com%5C64600e6767f4430880d655c67f4e5c49%5C5f10a_1440w.jpeg" alt="img"></p>
<p>其实简单理解就是在原始的CNN中10个feature map的话经过average pooling输出的不一定是一个值，而global average pooling输出的就一定是一个值</p>
<p>最后附上原文：<a href="https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/1312.4400.pdf">Network In Network</a></p>
</div></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">WangChen</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="https://wangchenhust.github.io/2020/04/06/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/Network%20in%20Network/">https://wangchenhust.github.io/2020/04/06/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/Network%20in%20Network/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank" rel="noopener">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://wangchenhust.github.io">MorningCoder</a>！</span></div></div><div class="post-meta__tag-list"></div><nav id="pagination"><div class="prev-post pull-left"><a href="/wangchenhust.github.io/2020/04/06/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/ResNet/"><i class="fa fa-chevron-left">  </i><span>深度学习/ResNet</span></a></div><div class="next-post pull-right"><a href="/wangchenhust.github.io/2020/04/06/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/AlexNet/"><span>深度学习/AlexNet</span><i class="fa fa-chevron-right"></i></a></div></nav></div></div><footer><div class="layout" id="footer"><div class="copyright">&copy;2013 - 2020 By WangChen</div><div class="framework-info"><span>驱动 - </span><a href="http://hexo.io" target="_blank" rel="noopener"><span>Hexo</span></a><span class="footer-separator">|</span><span>主题 - </span><a href="https://github.com/Molunerfinn/hexo-theme-melody" target="_blank" rel="noopener"><span>Melody</span></a></div><div class="busuanzi"><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><span id="busuanzi_container_page_pv"><i class="fa fa-file"></i><span id="busuanzi_value_page_pv"></span><span></span></span></div></div></footer><i class="fa fa-arrow-up" id="go-up" aria-hidden="true"></i><script src="https://cdn.jsdelivr.net/npm/animejs@latest/anime.min.js"></script><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-animate@latest/velocity.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-ui-pack@latest/velocity.ui.min.js"></script><script src="/wangchenhust.github.io/js/utils.js?version=1.7.0"></script><script src="/wangchenhust.github.io/js/fancybox.js?version=1.7.0"></script><script src="/wangchenhust.github.io/js/sidebar.js?version=1.7.0"></script><script src="/wangchenhust.github.io/js/copy.js?version=1.7.0"></script><script src="/wangchenhust.github.io/js/fireworks.js?version=1.7.0"></script><script src="/wangchenhust.github.io/js/transition.js?version=1.7.0"></script><script src="/wangchenhust.github.io/js/scroll.js?version=1.7.0"></script><script src="/wangchenhust.github.io/js/head.js?version=1.7.0"></script><script>if(/Android|webOS|iPhone|iPod|iPad|BlackBerry/i.test(navigator.userAgent)) {
  $('#nav').addClass('is-mobile')
  $('footer').addClass('is-mobile')
  $('#top-container').addClass('is-mobile')
}</script></body></html>