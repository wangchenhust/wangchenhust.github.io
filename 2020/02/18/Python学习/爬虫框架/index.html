<!DOCTYPE html><html lang="zh-Hans"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="description" content="Python学习/爬虫框架"><meta name="keywords" content=""><meta name="author" content="WangChen"><meta name="copyright" content="WangChen"><title>Python学习/爬虫框架 | MorningCoder</title><link rel="shortcut icon" href="/wangchenhust.github.io/melody-favicon.ico"><link rel="stylesheet" href="/wangchenhust.github.io/css/index.css?version=1.7.0"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css?version=1.7.0"><meta name="format-detection" content="telephone=no"><meta http-equiv="x-dns-prefetch-control" content="on"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><script>var GLOBAL_CONFIG = { 
  root: '/wangchenhust.github.io/',
  algolia: undefined,
  localSearch: undefined,
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  }
} </script><meta name="generator" content="Hexo 4.2.0"><link rel="alternate" href="/wangchenhust.github.io/atom.xml" title="MorningCoder" type="application/atom+xml">
</head><body><i class="fa fa-arrow-right" id="toggle-sidebar" aria-hidden="true"></i><div id="sidebar" data-display="true"><div class="toggle-sidebar-info text-center"><span data-toggle="切换文章详情">切换站点概览</span><hr></div><div class="sidebar-toc"><div class="sidebar-toc__title">目录</div><div class="sidebar-toc__progress"><span class="progress-notice">你已经读了</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar"></div></div><div class="sidebar-toc__content"></div></div><div class="author-info hide"><div class="author-info__avatar text-center"><img src="/wangchenhust.github.io/img/avatar.png"></div><div class="author-info__name text-center">WangChen</div><div class="author-info__description text-center">Stay hungry, stay foolish 主要涉及到编程（JS，Python，Linux等）和前端学习（HTML/CSS），用于个人整理知识点，回顾复习与反思</div><hr><div class="author-info-articles"><a class="author-info-articles__archives article-meta" href="/wangchenhust.github.io/archives"><span class="pull-left">文章</span><span class="pull-right">13</span></a><a class="author-info-articles__tags article-meta" href="/wangchenhust.github.io/tags"><span class="pull-left">标签</span><span class="pull-right">2</span></a><a class="author-info-articles__categories article-meta" href="/wangchenhust.github.io/categories"><span class="pull-left">分类</span><span class="pull-right">2</span></a></div></div></div><div id="content-outer"><div class="no-bg" id="top-container"><div id="page-header"><span class="pull-left"> <a id="site-name" href="/wangchenhust.github.io/">MorningCoder</a></span><i class="fa fa-bars toggle-menu pull-right" aria-hidden="true"></i><span class="pull-right menus">   <a class="site-page" href="/">Home</a><a class="site-page" href="/archives">Archives</a><a class="site-page" href="/tags">Tags</a><a class="site-page" href="/categories">Categories</a></span><span class="pull-right"></span></div><div id="post-info"><div id="post-title">Python学习/爬虫框架</div><div id="post-meta"><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2020-02-18</time></div></div></div><div class="layout" id="content-inner"><article id="post"><div class="article-container" id="post-content"><p><strong>Scrapy爬虫框架</strong></p>
<p>​        爬虫框架是实现爬虫功能的一个软件结构和功能组件集合；是一个半成品，能够帮助用户实现专业网络爬虫。</p>
<p>​        Scarpy是一个功能非常强大的爬虫框架。它不仅能便捷地构建request，还有强大的 selector 能够方便地解析 response，可以将爬虫工程化、模块化。<a id="more"></a></p>
<img src="C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20200216132325542.png" alt="image-20200216132325542" style="zoom: 50%;" />

<p>​        三条主要的数据流，ENGINE、DOWNLOADER、SCHEDULER在python中有现成模块，用户只需要对<u>SPIDER、ITEM PIPELINES</u>进行配置。</p>
<p><strong>组成</strong>：</p>
<ul>
<li><strong>引擎（Engine）</strong>：控制所有模块之间的数据流；根据条件触发事件（框架核心。</li>
<li><strong>下载器（Downloader）</strong>：根据请求下载网页内容，并将网页内容返回给引擎（Scrapy下载器是建立在twisted这个高效的异步模型上的）。</li>
<li><strong>调度器（Sceduler）</strong>：对所有爬取请求进行调度管理，接受引擎发过来的请求，压入队列中，并在引擎再次请求的时候返回。</li>
<li><strong>下载器中间件（Downloder Middleware）</strong>:位于引擎和下载器之间，可以修改、丢弃、新增请求或响应，目的是实施Engine、Sceduler和Downloader之间的用户可配置的控制。（反爬措施可以在这里加入）</li>
<li><strong>爬虫（Spider）</strong>：解析Downloader返回的响应；产生爬取项（即提取item）；产生额外的爬取请求。每个Spider处理一个（一些）特定网站。</li>
<li><strong>项目管道（Item Pipelines）</strong>：以流水线方式处理Spider产生的爬取项；由一组操作顺序组成，每个操作是一个Item Pipelines类型；可能的操作包括：清理、验证和查重爬取项中的HTML数据，将数据存储到数据库。</li>
<li><strong>爬虫中间件（Spider Middleware）</strong>：位于引擎和爬虫之间，主要工作是修改、丢弃、新增请求或爬取项，目的是对请求和爬取项的再处理。</li>
</ul>
<p><strong>Scrapy命令行</strong>：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&gt;scrapy&lt;command&gt;[options][args]</span><br></pre></td></tr></table></figure>

<p>命令行更容易自动化，适合脚本控制，给程序员使用</p>
<p><a href="https://www.cnblogs.com/zengsf/p/10039106.html" target="_blank" rel="noopener">常用命令</a>：</p>
<table>
<thead>
<tr>
<th>命令</th>
<th>说明</th>
<th>格式</th>
</tr>
</thead>
<tbody><tr>
<td>startproject</td>
<td>创建一个新工程</td>
<td>scrapy startproject <name>[dir]</td>
</tr>
<tr>
<td>genspider</td>
<td>创建一个爬虫</td>
<td>scrapy genspider [options]<name><domain></td>
</tr>
<tr>
<td>settings</td>
<td>获得爬虫配置的信息</td>
<td>scrapy settings[options]</td>
</tr>
<tr>
<td>crawl</td>
<td>运行一个爬虫</td>
<td>scrapy crawl<spider></td>
</tr>
<tr>
<td>list</td>
<td>列出工程中所有爬虫</td>
<td>scrapy list</td>
</tr>
<tr>
<td>shell</td>
<td>启动URL调试命令行</td>
<td>scrapy shell[url]</td>
</tr>
</tbody></table>
<p><strong>Scrapy爬虫的使用步骤</strong></p>
<ul>
<li><p>step1：创建一个工程和Spider模板</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&gt;scrapy startproject Projectname</span><br><span class="line">&gt;cd Projectname</span><br><span class="line">&gt;scrapy genspider example example.com</span><br><span class="line">进一步修改spiders&#x2F;example.py文件</span><br></pre></td></tr></table></figure>

<p>示例工程（python123demo）目录详解：</p>
<img src="C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20200216171046494.png" alt="image-20200216171046494" style="zoom: 50%;" />
</li>
<li><p>step2：编写Spider</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">配置stocks.py文件</span><br><span class="line">修改对返回页面的处理</span><br><span class="line">修改对新增URL爬取请求处理</span><br></pre></td></tr></table></figure>
</li>
<li><p>step3：编写Item Piplline</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">配置pipeline.py文件</span><br><span class="line">定义对爬取项（Scraped Item）的处理类</span><br><span class="line">配置ITEM_PIPELINE选项</span><br></pre></td></tr></table></figure>
</li>
<li><p>step4：优化配置策略（修改settings.py)</p>
</li>
</ul>
<p>三个主要类</p>
<ul>
<li><strong>Request类</strong></li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">scrapy</span>.<span class="title">http</span>.<span class="title">Request</span><span class="params">()</span></span></span><br></pre></td></tr></table></figure>

<p>Request对象表示一个HTTP请求，由Spider生成，由Downloader执行。</p>
<table>
<thead>
<tr>
<th>属性或方法</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td>.url</td>
<td>Request对应的请求URL地址</td>
</tr>
<tr>
<td>.method</td>
<td>对应的请求方法，’GET’ ‘POST’等</td>
</tr>
<tr>
<td>.headers</td>
<td>字典类型风格的请求头</td>
</tr>
<tr>
<td>.body</td>
<td>请求内容主体，字符串类型</td>
</tr>
<tr>
<td>.meta</td>
<td>用户添加的扩展信息，在Scrapy内部模块间传递信息使用</td>
</tr>
<tr>
<td>.copy()</td>
<td>复制该请求</td>
</tr>
</tbody></table>
<ul>
<li><strong>Response类</strong></li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">scrapy</span>.<span class="title">http</span>.<span class="title">Response</span><span class="params">()</span></span></span><br></pre></td></tr></table></figure>

<p>Response对象表示一个HTTP响应，由Downloader生成，由Spider处理。</p>
<table>
<thead>
<tr>
<th>属性或方法</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td>.url</td>
<td>Response对应的URL地址</td>
</tr>
<tr>
<td>.status</td>
<td>HTTP状态码，默认是200</td>
</tr>
<tr>
<td>.headers</td>
<td>Response对应的头部信息</td>
</tr>
<tr>
<td>.body</td>
<td>Response对应的内容信息，字符串类型</td>
</tr>
<tr>
<td>.flags</td>
<td>一组标记</td>
</tr>
<tr>
<td>.request</td>
<td>产生Response类型对应的Request对象</td>
</tr>
<tr>
<td>.copy()</td>
<td>复制该响应</td>
</tr>
</tbody></table>
<ul>
<li><strong>Item类</strong></li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">scrapy</span>.<span class="title">item</span>.<span class="title">Item</span><span class="params">()</span></span></span><br></pre></td></tr></table></figure>

<p>​        Item对象表示一个从HTML页面中提取的信息内容，由Spider生成，由Item Pipeline处理，Item类似字典类型，可以按照字典类型操作。</p>
<p><strong>提取信息方法</strong></p>
<p>Scrapy爬虫支持多种HTML信息提取方法：<br>• Beautiful Soup<br>• lxml<br>• re<br>• XPath Selector<br>• CSS Selector</p>
<p><strong>requests与Scrapy比较</strong></p>
<p>相同点：</p>
<ol>
<li>都可以进行页面请求和爬取；</li>
<li>可用性好，文档丰富；</li>
<li>都没有处理JS、提交表单、应对验证码等功能。</li>
</ol>
<p>不同点</p>
<table>
<thead>
<tr>
<th>Requests</th>
<th>Scrapy</th>
</tr>
</thead>
<tbody><tr>
<td>页面级爬虫</td>
<td>网站级爬虫</td>
</tr>
<tr>
<td>功能库</td>
<td>框架</td>
</tr>
<tr>
<td>并发性考虑不足，性能较差</td>
<td>并发性好，性能较高</td>
</tr>
<tr>
<td>重点在于页面下载</td>
<td>重点在于爬虫结构</td>
</tr>
<tr>
<td>定制灵活</td>
<td>一般定制灵活，深度定制困难</td>
</tr>
<tr>
<td>上手十分简单</td>
<td>入门稍难</td>
</tr>
</tbody></table>
<p>应用范围：非常小的需求用requests库，否则用Scrapy框架；定制程度高时可选用requests自搭框架。</p>
</div></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">WangChen</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="https://wangchenhust.github.io/2020/02/18/Python%E5%AD%A6%E4%B9%A0/%E7%88%AC%E8%99%AB%E6%A1%86%E6%9E%B6/">https://wangchenhust.github.io/2020/02/18/Python%E5%AD%A6%E4%B9%A0/%E7%88%AC%E8%99%AB%E6%A1%86%E6%9E%B6/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank" rel="noopener">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://wangchenhust.github.io">MorningCoder</a>！</span></div></div><div class="post-meta__tag-list"></div><nav id="pagination"><div class="prev-post pull-left"><a href="/wangchenhust.github.io/2020/04/06/Mysql%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"><i class="fa fa-chevron-left">  </i><span>Mysql学习笔记</span></a></div><div class="next-post pull-right"><a href="/wangchenhust.github.io/2020/02/18/Python%E5%AD%A6%E4%B9%A0/%E7%88%AC%E8%99%AB%E7%AE%80%E4%BB%8B/"><span>Python学习/爬虫简介</span><i class="fa fa-chevron-right"></i></a></div></nav></div></div><footer><div class="layout" id="footer"><div class="copyright">&copy;2013 - 2020 By WangChen</div><div class="framework-info"><span>驱动 - </span><a href="http://hexo.io" target="_blank" rel="noopener"><span>Hexo</span></a><span class="footer-separator">|</span><span>主题 - </span><a href="https://github.com/Molunerfinn/hexo-theme-melody" target="_blank" rel="noopener"><span>Melody</span></a></div><div class="busuanzi"><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><span id="busuanzi_container_page_pv"><i class="fa fa-file"></i><span id="busuanzi_value_page_pv"></span><span></span></span></div></div></footer><i class="fa fa-arrow-up" id="go-up" aria-hidden="true"></i><script src="https://cdn.jsdelivr.net/npm/animejs@latest/anime.min.js"></script><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-animate@latest/velocity.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-ui-pack@latest/velocity.ui.min.js"></script><script src="/wangchenhust.github.io/js/utils.js?version=1.7.0"></script><script src="/wangchenhust.github.io/js/fancybox.js?version=1.7.0"></script><script src="/wangchenhust.github.io/js/sidebar.js?version=1.7.0"></script><script src="/wangchenhust.github.io/js/copy.js?version=1.7.0"></script><script src="/wangchenhust.github.io/js/fireworks.js?version=1.7.0"></script><script src="/wangchenhust.github.io/js/transition.js?version=1.7.0"></script><script src="/wangchenhust.github.io/js/scroll.js?version=1.7.0"></script><script src="/wangchenhust.github.io/js/head.js?version=1.7.0"></script><script>if(/Android|webOS|iPhone|iPod|iPad|BlackBerry/i.test(navigator.userAgent)) {
  $('#nav').addClass('is-mobile')
  $('footer').addClass('is-mobile')
  $('#top-container').addClass('is-mobile')
}</script></body></html>